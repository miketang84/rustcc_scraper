https://github.com/funlennysub/diffogus
-->>-->>
Repository files navigation README MIT license diffogus Rust crate to calculate the difference between 2 instances of the same type Features Simple diff of basic rust types All integer types All floats Vectors of elements that implement Diffable HashMaps where value implements Diffable Options of types that implement Diffable Diff between 2 instances of a struct that implements Diffable Implemented manually or with #[derive(Diff)] ⚠️ Currently only structs with named fields are supported Serialize your diffs with serde feature flag
======>
https://tagedan.github.io/posts/terminal_rendering.html
-->>-->>
Create a 3D-Terminal Renderer Author: Tage Danielsson Date: 2024-11-05 Introduction When me and Felicia set out to
build a 3D-terminal game we needed, of course, a 3D renderer! So I started to create one.
In this blog post I will show you how to build one yourself, from scratch. General Idea The general idea is that we will shot a ray through a pixel on
our screen (in our case a position in the terminal), then we will calculate what triangle
in a mesh that ray will hit and lastly we will draw the color of the triangle
to the screen (using ansi-codes for coloring the characters in the terminal). Setup Make sure that you have rust and cargo installed .
Then run Cargo new terminal-renderer Then setup your folder structure like this: terminal-renderer
+ -- Cargo.toml + -- src |   + -- lib.rs |   + -- main.rs |   + -- math |   |   + -- mod.rs |   + -- renderer |   |   + -- mod.rs Then add the dependencies ( term_size and vec3-rs ) to the Cargo.toml file: [dependencies] vec3-rs = "0.1.6" # Vector operations term_size = "0.3.2" # Getting terminal size Add includes to lib.rs pub mod renderer; pub mod math; Rays through screen As mentioned before we want to "shoot" rays through every pixel on the screen.
Theese rays will be represented as a origin point and a ray direction. We start by
creating a struct for this in the math module and implement a new function for it . // math/mod.rs use vec3_rs::Vector3; pub struct Ray { pub origin: Vector3< f64 >, pub dir: Vector3< f64 >,
} impl Ray { pub fn new (origin: Vector3< f64 >, dir: Vector3< f64 >) -> Self { Self {
            origin,
            dir,
        }
    }
} Then we need to iterate over the pixels on the screen
and construct a ray going through the pixel from a fixed origin some distance behind.
To do this we will create a struct called Screen that will hold the height,
width and focus distance. Screen will also be the struct for which
we define all the rendering methods later. // renderer/mod.rs use term_size; pub struct Screen {
    w: usize ,
    h: usize ,
    focus_dist: f64 ,
} impl Screen { pub fn new (focus_dist: f64 ) -> Self { let mut screen = Self {
            w: 0 ,
            h: 0 ,
            focus_dist,
        };

        screen. update_size (); println! ( "\x1b[?25l" ); // Hide cursor println! ( "\x1b[2J" ); // Clear terminal return screen;
    } pub fn update_size (& mut self ) { if let Some (s) = term_size:: dimensions () { self .w = s. 0 ; self .h = s. 1 ;
        }
    }
} The ansi codes "\x1b[?25l" and "\x1b[2J" hides the cursor and clears
the terminal respectively.
You will see more of theese types of codes later. Note that focus_dist is what determines the feild of view (fov).
A lower focus distance will give a higher feild of view as
shown by the image below: We will also need a struct which hold the position of our origin.
We will call this struct Camera and later we will add a rotation to it aswell. // renderer/mod.rs use vec3_rs::Vector3; pub struct Camera { pub pos: Vector3< f64 >,
} impl Camera < f64 > { pub fn new (pos: Vector3< f64 >) -> Self { Self {
            pos,
        }
    }
} Now we can finally create our render method for the Screen struct. // renderer/mod.rs use crate::math; impl Screen { pub fn render (& self , camera: &Camera) { for row in 0 .. self .h { for col in 0 .. self .w { let ray_o = camera.pos; // Ray Origin let row = (row as f64 / self .h as f64 ) * 2 . - 1 .; // Scale from -1 to +1 let col = (col as f64 / self .w as f64 ) * 2 . - 1 .; // --||-- // Ray let ray = math::Ray:: new (ray_o, Vector3:: new (col, row, self .focus_dist));
              }
          }
      }
} Okay, we have now constructed our rays, they will have the same origin as the camera and
will have the direction of the column and row it is shooting through.
Note that the focus distance is the z-coordinate of the direction and
that we scale the screen coordinates from -1 to 1; Adding Triangles All Right we have constructed our Ray s but they have nothing to hit at
the moment. For this we're going to define a Triangle Struct and a Mesh Struct // math/mod.rs use crate::math; use std::rc::Rc; pub struct Tri { pub v0: Vector3< f64 >, pub v1: Vector3< f64 >, pub v2: Vector3< f64 >,
} pub struct Mesh { pub tris: Rc<[Tri]>,
} impl Tri { pub fn new (v0: Vector3< f64 >, v1: Vector3< f64 >, v2: Vector3< f64 >) -> Self { Self { v0, v1, v2 }
    }
} impl Mesh { pub fn new (tris: Vec <Tri>) -> Self { Self { tris: tris. into () }
    }
} We will also add a Mesh as a parameter to the render function and loop
through the triangles for each Ray to determine which one it hits. // renderer/mod.rs impl Screen { pub fn render (& self , camera: &Camera, mesh: &math::Mesh) { for row in 0 .. self .h { for col in 0 .. self .w { let ray_o = camera.pos; // Ray Origin let row = (row as f64 / self .h as f64 ) * 2 . - 1 .; // Scale from -1 to +1 let col = (col as f64 / self .w as f64 ) * 2 . - 1 .; // --||-- // Ray let ray = math::Ray:: new (ray_o, Vector3:: new (col, row, self .focus_dist)); // Get hit triangle and distance to hit let (hit_tri, distance) = { let mut hit_tri = None ; let mut dist = f64 ::MAX; for tri in mesh.tris. iter () { if let Some (d) = tri. hit (ray) { if d < dist {
                                dist = d;
                                hit_tri = Some (tri);
                            };
                        };
                    }
                    (hit_tri, dist)
                  };

              }
          }
      }
} Okey, we now have a loop that will calculate the hit triangle and the distance to the hit.
But we used a method hit on our triangle which we haven't defined yet. Determining triangle hit We will now define the before mentioned hit method. It will be an implementation of the möller-trumbore algorithm for this we will use something called the barycentric coordinates to determine a triangle hit.
Barycentric coordinates is a way of representing coordinates in terms
of the areas of each triangle formed by the coordinate and the opposite side of the triangle.
Like in the picture below This type of coordinate is useful because it helps us check if a ray
hits the triangle by first checking where the ray hit's the plane of the triangle and
then that none of the barycentric coordinates are negative
(A negative area would mean that the point is outside of the triangle)
This method is called the möller-trumbore algorithm. You can read more about it here // math/mod.rs impl Tri { // Möller-Trumbore algo (https://www.scratchapixel.com/lessons/3d-basic-rendering/ray-tracing-rendering-a-triangle/moller-trumbore-ray-triangle-intersection.html) pub fn hit (& self , ray: &Ray) -> Option < f64 > { let e1 = self .v1 - self .v0; let e2 = self .v2 - self .v0; let p = ray.dir. cross (&e2); let det = e1. dot (&p); const EPSILON: f64 = 0.001 ; // If determinant is close to zero the ray and triangle are parallel if det. abs () < EPSILON { return None ;
        } let inv_det = 1 . / det; let t = ray.origin - self .v0; let u = t. dot (&p) * inv_det; if u < 0 . || u > 1 . { return None ;
        }; let q = t. cross (&e1); let v = ray.dir. dot (&q) * inv_det; if (v < 0 . || u + v > 1 .) { return None ;
        } let t = e2. dot (&q) * inv_det; return Some (t);
    }

} This solution is derived from the equation of the point using barycentric
coordinates (P = A + u(B-A)+ v(C-A)) and the parametarised equation of the line
(P = O + tD). See Wikipedia and Scratchapixel to learn more. But that's it for the hit function. Save pixel colors to buffer Now we will go back to the render function and save the color of
the closest hit trangle to a buffer. // renderer/mod.rs impl Screen { pub fn render (& self , camera: &Camera, mesh: &math::Mesh) { // Init buffer let buffer = Vec :: with_capacity ( self .w * self .h); for row in 0 .. self .h { for col in 0 .. self .w { let ray_o = camera.pos; // Ray Origin let row = (row as f64 / self .h as f64 ) * 2 . - 1 .; // Scale from -1 to +1 let col = (col as f64 / self .w as f64 ) * 2 . - 1 .; // --||-- // Ray let ray = math::Ray:: new (ray_o, Vector3:: new (col, row, self .focus_dist)); // Get hit triangle and distance to hit let (hit_tri, distance) = { let mut hit_tri = None ; let mut dist = f64 ::MAX; for tri in mesh.tris. iter () { if let Some (d) = tri. hit (&ray) { if d < dist {
                                dist = d;
                                hit_tri = Some (tri);
                            };
                        };
                    }
                    (hit_tri, dist)
                }; if let Some (t) = hit_tri { // push to buffer buffer. push (t.color);
                } else {
                    buffer. push (Vector3:: new ( 0 ., 0 ., 0 .));
                }
            }
        }
    }
} For this we need to add a color feild to our triangle struct // math/mod.rs pub struct Tri { pub v0: Vector3< f64 >, pub v1: Vector3< f64 >, pub v2: Vector3< f64 >, pub color: Vector3< f64 >,
} impl Tri { pub fn new (v0: Vector3< f64 >, v1: Vector3< f64 >, v2: Vector3< f64 >, color: Vector3< f64 >) -> Self { Self { v0, v1, v2, color }
    }
} Showing buffer To show the buffer we will add a flush method on the screen
struct and call it at the end of the render function. // renderer/mod.rs impl Screen { pub fn render (& self , camera: &Camera, mesh: &math::Mesh) { let mut buffer = Vec :: with_capacity ( self .w * self .h); for row in 0 .. self .h { for col in 0 .. self .w { let ray_o = camera.pos; // Ray Origin let row = (row as f64 / self .h as f64 ) * 2 . - 1 .; // Scale from -1 to +1 let col = (col as f64 / self .w as f64 ) * 2 . - 1 .; // --||-- // Ray let ray = math::Ray:: new (ray_o, Vector3:: new (col, row, self .focus_dist)); // Get hit triangle and distance to hit let (hit_tri, distance) = { let mut hit_tri = None ; let mut dist = f64 ::MAX; for tri in mesh.tris. iter () { if let Some (d) = tri. hit (&ray) { if d < dist {
                                dist = d;
                                hit_tri = Some (tri);
                            };
                        };
                    }
                    (hit_tri, dist)
                }; if let Some (t) = hit_tri {
                    buffer. push (t.color);
                } else {
                    buffer. push (Vector3:: new ( 0 ., 0 ., 0 .));
                }
            }
        } self . flush (&buffer);
    } pub fn flush (& self , buffer: &[Vector3< f64 >]) { print! ( "\x1b[H" ); // Move curor Home for row in 0 .. self .h { for col in 0 .. self .w { let color = buffer[row * self .w + col]; print! ( "\x1b[48;2;{r};{g};{b}m " ,
                    r = color. get_x () as u8 ,
                    g = color. get_y () as u8 ,
                    b = color. get_z () as u8 )
            } print! ( "\r\n" );
        } print! ( "\x1b[48;2;255;255;255m" );
    }
} The flush starts by moving the cursor "home" (to the upper left corner) by printing the
ansi code "\x1b[H" to the terminal, "\x1b" is a escape character and
"[H" moves the cursor home. We then iterate through the buffer and prints a space with the rigth color.
To set the color we also use ansi-codes, "[48" means that we will set the background
color, ";2" means that the color will be rgb and then we can set the rgb-values
using string formatting. To learn more about terminal colors, This stac-overflow conversation is a great resource. After each row we also print "\r\n" to move to the next line. Test it To test the program add a screen, camera and mesh to your main function
and run render on the screen. // main.rs use vec3_rs::Vector3; fn main () { let screen = terminal_renderer::renderer::Screen:: new ( 0.1 ); let camera = terminal_renderer::renderer::Camera:: new (Vector3:: new ( 0 ., 0 ., - 2 .)); use terminal_renderer::math::Tri as T; let mesh = vec! [T:: new (
        Vector3:: new ( 0 ., - 5 ., 0 .),
        Vector3:: new ( 10 ., 5 ., 0 .),
        Vector3:: new ( 0 ., 5 ., 0 .),
        Vector3:: new ( 255 ., 255 ., 0 .),
    )]; let mesh = terminal_renderer::math::Mesh:: new (mesh);
    screen. render (&camera, &mesh);
} And then run the program.
You should see this in your terminal. A flat triangle! ... Simple shading To do some simple shading we will compare theray direction to the triangle normal.
If the angle is large we will darken the color,
If we are looking straight at it we will include the full color.
We will also darken far away points creating a sort of fog effect. // renderer/mod.rs // in render method if let Some (t) = hit_tri { let normal = t. normal (); let inv_dir = ray.dir * - 1 .; let a = normal. angle (&ray.dir). min (normal. angle (&inv_dir)); let f = 1.0 - a. abs () / PI; const RENDER_DIST: f64 = 75 .; let color = t.color * f * ((RENDER_DIST - distance) / RENDER_DIST). max ( 0 .);
    buffer. push (color);
} else {
    buffer. push (Vector3:: new ( 0 ., 0 ., 0 .));
} To really see this effect clearly we will need a more complicated shape.
Let's make a rotating triangle! // main.rs use vec3_rs::Vector3; fn main () { let screen = terminal_renderer::renderer::Screen:: new ( 1 .); let camera = terminal_renderer::renderer::Camera:: new (Vector3:: new ( 0 ., 0 ., - 6 .)); use terminal_renderer::math::Tri as T; let mut t : f64 = 0.0 ; loop {
        t += 0.01 ; let mesh = vec! [T:: new (
            Vector3:: new (-t. cos () * 5 ., - 5 ., -t. sin () * 5 .),
            Vector3:: new ( 0 ., 5 ., 0 .),
            Vector3:: new (t. cos () * 5 ., - 5 ., t. sin () * 5 .),
            Vector3:: new ( 0 ., 255 ., 0 .),
        )]; let mesh = terminal_renderer::math::Mesh:: new (mesh);
        screen. render (&camera, &mesh);
    }
} Run this and you should see a rotating triangle with some simple shading. Conclusion In this post we have learned how to build a simple 3D-renderer for the terminal.
In the next blog-post I will
build a 3D-file loader so that we can load files and view them in the terminal.
We will also add camera rotation so that we can move and rotate the camera around a scene. Source code at this point Our 3D-Terminal Game
======>
https://github.com/TermTrack/TermTrack
-->>-->>
Repository files navigation README MIT license TermTrack A terminal-rendered 3D platforming/maze game with focus on speedrunning and custom level creation termtrack.mp4 Requirements You will need a terminal to play this game. But all teminals are not created the same. For the moment we recommend that you use windows-terminal availible in the microsoft store (further testing will be done in the future) Install Windows Install the zip-folder from the releases section or using the link: https://tagedan.github.io/TermTrack/TERMTRACK_WINDOWS.zip Extract it into a folder of your choice. Linux Install the zip-folder from the releases section or using the link: https://tagedan.github.io/TermTrack/TERMTRACK_LINUX.zip Extract it into a folder of your choice. Run In the extracted "TermTrack" folder run: example/TermTrack > termtrack level_pack_0 where level_pack_0 can be substituted for the name of the folder containing the levels you want to play. From source Unfortunaly, due to the need of a secret salt to validate the leaderboard you cannot build this project from source and expect it to work with the leaderboard. We are working on a seperate branch where the leaderboard will instead be local and therefore can be built from source. Level Layout/Creation A level is represented by a textfile with the format level_name.txt (or any other file extention, everything up until the last '.' will be the level name)
To build a level you write characters that will represent the grid of the actual level. There are 8 grid-types at the moment, these are: 'S' (start grid) 'E' (end grid) 'X' (wall) 'x' (half-wall / stair) 'v' (spike) '.' (floor) ' ' (hole) 'e' (enemy / angry-pixel spawn) There is also the floor seperator represented by a new row containing only sep after wich the next floor can be built. Example_level.txt: XXX
XSX
XvX
X.X
XxX
XXX
sep
XXXXXXX
X....EX
X.XXXXX
X.X
X X
XXX This level will have two floors with the lower floor containing the start and the stair to the second floor as well as a spike between them and the upper floor containing the end.
To then play the lavel you need to put it into a folder next to termtrack.exe and then run: TermTrack > termtrack < level_folder_name > replacing <level_folder_name> with the name of your folder. Known bugs Lazy error handling of network-requests leads to game crashing when offline.
Leaderboard validation is faulty.
Terminal focus can be hard to regain when lost.
Music crackling on high load. Future plans Standalone Leaderboard Enemy sound Level Editor Discord Bot 3D-object file loader Support If you have any questions, please look at the github-discussions tab to see if it has already been answered or start a new discussion. Contributing Feel free to create a issue if you have a feature that you would like to see implemented. You are also free to fork the project and make a pr if you have made an improvement. Acknowledgements abbfelarb - Owner TageDan - Owner GustavPetterssonBjorklund - For suggesting security actions https://patorjk.com/software/taag/ - for generating the title-art The Rust programming language and The terminal :) - for making this possible
======>
https://github.com/abbfelarb
-->>-->>
Popular repositories Loading flappyMoa flappyMoa Public JavaScript talaBot talaBot Public JavaScript 92
      contributions
        in the last year No contributions on November 5th. No contributions on November 12th. No contributions on November 19th. No contributions on November 26th. No contributions on December 3rd. No contributions on December 10th. No contributions on December 17th. No contributions on December 24th. No contributions on December 31st. No contributions on January 7th. No contributions on January 14th. No contributions on January 21st. No contributions on January 28th. No contributions on February 4th. No contributions on February 11th. No contributions on February 18th. No contributions on February 25th. No contributions on March 3rd. No contributions on March 10th. No contributions on March 17th. No contributions on March 24th. No contributions on March 31st. No contributions on April 7th. No contributions on April 14th. No contributions on April 21st. No contributions on April 28th. No contributions on May 5th. No contributions on May 12th. No contributions on May 19th. No contributions on May 26th. No contributions on June 2nd. No contributions on June 9th. No contributions on June 16th. No contributions on June 23rd. No contributions on June 30th. No contributions on July 7th. No contributions on July 14th. No contributions on July 21st. No contributions on July 28th. No contributions on August 4th. No contributions on August 11th. No contributions on August 18th. No contributions on August 25th. No contributions on September 1st. No contributions on September 8th. No contributions on September 15th. No contributions on September 22nd. 4 contributions on September 29th. No contributions on October 6th. No contributions on October 13th. No contributions on October 20th. No contributions on October 27th. No contributions on November 3rd. No contributions on November 6th. No contributions on November 13th. No contributions on November 20th. No contributions on November 27th. No contributions on December 4th. No contributions on December 11th. No contributions on December 18th. No contributions on December 25th. No contributions on January 1st. No contributions on January 8th. No contributions on January 15th. No contributions on January 22nd. No contributions on January 29th. No contributions on February 5th. No contributions on February 12th. No contributions on February 19th. No contributions on February 26th. No contributions on March 4th. No contributions on March 11th. No contributions on March 18th. No contributions on March 25th. No contributions on April 1st. No contributions on April 8th. No contributions on April 15th. No contributions on April 22nd. No contributions on April 29th. No contributions on May 6th. No contributions on May 13th. No contributions on May 20th. No contributions on May 27th. No contributions on June 3rd. No contributions on June 10th. No contributions on June 17th. No contributions on June 24th. No contributions on July 1st. No contributions on July 8th. No contributions on July 15th. No contributions on July 22nd. No contributions on July 29th. No contributions on August 5th. No contributions on August 12th. No contributions on August 19th. No contributions on August 26th. No contributions on September 2nd. No contributions on September 9th. No contributions on September 16th. No contributions on September 23rd. 7 contributions on September 30th. No contributions on October 7th. No contributions on October 14th. No contributions on October 21st. No contributions on October 28th. No contributions on November 4th. No contributions on November 7th. No contributions on November 14th. No contributions on November 21st. No contributions on November 28th. No contributions on December 5th. No contributions on December 12th. No contributions on December 19th. No contributions on December 26th. No contributions on January 2nd. No contributions on January 9th. No contributions on January 16th. No contributions on January 23rd. No contributions on January 30th. No contributions on February 6th. No contributions on February 13th. No contributions on February 20th. No contributions on February 27th. No contributions on March 5th. No contributions on March 12th. No contributions on March 19th. No contributions on March 26th. No contributions on April 2nd. No contributions on April 9th. 2 contributions on April 16th. No contributions on April 23rd. No contributions on April 30th. No contributions on May 7th. No contributions on May 14th. No contributions on May 21st. No contributions on May 28th. No contributions on June 4th. No contributions on June 11th. No contributions on June 18th. No contributions on June 25th. No contributions on July 2nd. No contributions on July 9th. No contributions on July 16th. No contributions on July 23rd. No contributions on July 30th. No contributions on August 6th. No contributions on August 13th. No contributions on August 20th. 1 contribution on August 27th. 4 contributions on September 3rd. No contributions on September 10th. 1 contribution on September 17th. 2 contributions on September 24th. 1 contribution on October 1st. 1 contribution on October 8th. No contributions on October 15th. 6 contributions on October 22nd. No contributions on October 29th. No contributions on November 5th. No contributions on November 8th. No contributions on November 15th. No contributions on November 22nd. No contributions on November 29th. No contributions on December 6th. No contributions on December 13th. No contributions on December 20th. No contributions on December 27th. No contributions on January 3rd. No contributions on January 10th. No contributions on January 17th. No contributions on January 24th. No contributions on January 31st. No contributions on February 7th. No contributions on February 14th. No contributions on February 21st. No contributions on February 28th. No contributions on March 6th. No contributions on March 13th. No contributions on March 20th. No contributions on March 27th. No contributions on April 3rd. No contributions on April 10th. No contributions on April 17th. No contributions on April 24th. No contributions on May 1st. No contributions on May 8th. No contributions on May 15th. No contributions on May 22nd. No contributions on May 29th. No contributions on June 5th. No contributions on June 12th. No contributions on June 19th. No contributions on June 26th. No contributions on July 3rd. No contributions on July 10th. No contributions on July 17th. No contributions on July 24th. No contributions on July 31st. No contributions on August 7th. No contributions on August 14th. No contributions on August 21st. 3 contributions on August 28th. 1 contribution on September 4th. No contributions on September 11th. No contributions on September 18th. 3 contributions on September 25th. No contributions on October 2nd. No contributions on October 9th. No contributions on October 16th. No contributions on October 23rd. No contributions on October 30th. No contributions on November 6th. No contributions on November 9th. No contributions on November 16th. No contributions on November 23rd. No contributions on November 30th. No contributions on December 7th. No contributions on December 14th. No contributions on December 21st. No contributions on December 28th. No contributions on January 4th. No contributions on January 11th. No contributions on January 18th. No contributions on January 25th. No contributions on February 1st. No contributions on February 8th. No contributions on February 15th. No contributions on February 22nd. No contributions on February 29th. No contributions on March 7th. No contributions on March 14th. No contributions on March 21st. No contributions on March 28th. No contributions on April 4th. No contributions on April 11th. 7 contributions on April 18th. No contributions on April 25th. No contributions on May 2nd. No contributions on May 9th. No contributions on May 16th. No contributions on May 23rd. No contributions on May 30th. No contributions on June 6th. No contributions on June 13th. No contributions on June 20th. No contributions on June 27th. No contributions on July 4th. No contributions on July 11th. No contributions on July 18th. No contributions on July 25th. No contributions on August 1st. No contributions on August 8th. No contributions on August 15th. No contributions on August 22nd. No contributions on August 29th. No contributions on September 5th. No contributions on September 12th. No contributions on September 19th. 4 contributions on September 26th. 6 contributions on October 3rd. No contributions on October 10th. No contributions on October 17th. No contributions on October 24th. No contributions on October 31st. No contributions on November 10th. No contributions on November 17th. No contributions on November 24th. No contributions on December 1st. No contributions on December 8th. No contributions on December 15th. No contributions on December 22nd. No contributions on December 29th. No contributions on January 5th. No contributions on January 12th. No contributions on January 19th. No contributions on January 26th. No contributions on February 2nd. No contributions on February 9th. No contributions on February 16th. No contributions on February 23rd. No contributions on March 1st. No contributions on March 8th. No contributions on March 15th. No contributions on March 22nd. No contributions on March 29th. No contributions on April 5th. 8 contributions on April 12th. 5 contributions on April 19th. No contributions on April 26th. No contributions on May 3rd. No contributions on May 10th. No contributions on May 17th. No contributions on May 24th. No contributions on May 31st. No contributions on June 7th. No contributions on June 14th. No contributions on June 21st. No contributions on June 28th. No contributions on July 5th. No contributions on July 12th. No contributions on July 19th. No contributions on July 26th. No contributions on August 2nd. No contributions on August 9th. No contributions on August 16th. No contributions on August 23rd. No contributions on August 30th. No contributions on September 6th. No contributions on September 13th. 2 contributions on September 20th. 2 contributions on September 27th. No contributions on October 4th. 7 contributions on October 11th. No contributions on October 18th. No contributions on October 25th. No contributions on November 1st. No contributions on November 11th. No contributions on November 18th. No contributions on November 25th. No contributions on December 2nd. No contributions on December 9th. No contributions on December 16th. No contributions on December 23rd. No contributions on December 30th. No contributions on January 6th. No contributions on January 13th. No contributions on January 20th. No contributions on January 27th. No contributions on February 3rd. No contributions on February 10th. No contributions on February 17th. No contributions on February 24th. No contributions on March 2nd. No contributions on March 9th. No contributions on March 16th. No contributions on March 23rd. No contributions on March 30th. No contributions on April 6th. No contributions on April 13th. No contributions on April 20th. No contributions on April 27th. No contributions on May 4th. No contributions on May 11th. No contributions on May 18th. No contributions on May 25th. No contributions on June 1st. No contributions on June 8th. No contributions on June 15th. No contributions on June 22nd. No contributions on June 29th. No contributions on July 6th. No contributions on July 13th. No contributions on July 20th. No contributions on July 27th. No contributions on August 3rd. No contributions on August 10th. No contributions on August 17th. No contributions on August 24th. No contributions on August 31st. No contributions on September 7th. No contributions on September 14th. No contributions on September 21st. 10 contributions on September 28th. No contributions on October 5th. 5 contributions on October 12th. No contributions on October 19th. No contributions on October 26th. No contributions on November 2nd. Contribution Graph Day of Week November Nov December Dec January Jan February Feb March Mar April Apr May May June Jun July Jul August Aug September Sep October Oct Sunday Sun Monday Mon Tuesday Tue Wednesday Wed Thursday Thu Friday Fri Saturday Sat Learn how we count contributions Less No contributions. Low contributions. Medium-low contributions. Medium-high contributions. High contributions. More 2024 2023 2022 Contribution activity November 2024 abbfelarb has no activity
          yet for this period. Loading Show more activity Seeing something unexpected? Take a look at the GitHub profile guide .
======>
https://github.com/memorysafety/rav1d
-->>-->>
Repository files navigation README BSD-2-Clause license rav1d rav1d is an AV1 cross-platform decoder, open-source, and focused on speed
and correctness. It is a Rust port of dav1d . Building rav1d is written in Rust and uses the standard Rust toolchain to build. The Rust
toolchain can be installed by going to https://rustup.rs . The rav1d library
builds on stable Rust for x86 , x86_64 , and aarch64 , but currently
requires a nightly compiler for arm and riscv64 . The project is configured
to use a nightly compiler by default via rust-toolchain.toml , but a stable
library build can be made with the +stable cargo flag. For x86 targets, you'll also need to install nasm in order
to build with assembly support. A release build can then be made using cargo: cargo build --release For development purposes you may also want to use the opt-dev profile, which
runs faster than a regular debug build but has all debug checks still enabled: cargo build --profile opt-dev To build just librav1d using a stable compiler: cargo +stable build --lib --release Feature Flags The following feature flags are supported: asm - Enables optimized assembly routines, if available for the target
platform. bitdepth_8 - Enables support for 8 bitdepth decoding. bitdepth_16 - Enables support for 10 and 12 bitdepth decoding. All of these features are enabled by default. In order to build a version of librav1d that disables one or more of these features use the --no-default-features flag in combination with the --features flag to enable
any desired features. For example, to build without assembly routines, which is
useful when testing the Rust fallback functions, do the following: cargo build --no-default-features --features= " bitdepth_8,bitdepth_16 " Cross-Compiling rav1d can be cross-compiled for a target other than the host platform using the cargo --target flag. This will require passing additional arguments to rustc to tell it what linker to use. This can be done by setting the RUSTFLAGS enviroment variable and specifying the linker compiler flag. For
example, compiling for aarch64-unknown-linux-gnu from an Ubuntu Linux machine
would be done as follows: RUSTFLAGS= " -C linker=aarch64-linux-gnu-gcc " cargo build --target aarch64-unknown-linux-gnu If you're cross-compiling in order to run tests under QEMU ( qemu-*-static )
you'll also need to specify the +crt-static target feature. RUSTFLAGS= " -C target-feature=+crt-static -C linker=aarch64-linux-gnu-gcc " cargo build --target aarch64-unknown-linux-gnu This will require installing the rustup component for the target platform and
the appropriate cross-platform compiler/linker toolchain for your target
platform. Examples of how we cross-compile rav1d in CI can be found in .github/workflows/build-and-test-qemu.yml . The following targets are currently supported: x86_64-unknown-linux-gnu i686-unknown-linux-gnu armv7-unknown-linux-gnueabihf aarch64-unknown-linux-gnu riscv64gc-unknown-linux-gnu Running Tests Currently we use the original Meson test suite for
testing the Rust port. This means you'll need to have Meson
installed to run tests. To setup and run the tests, do the following: First, build rav1d using cargo . You'll need to do this step manually before
running any tests because it is not built automatically when tests are run. It's
recommended to run tests with either the release or opt-dev profile as the
debug build runs slowly and often causes tests to timeout. The opt-dev profile
is generally ideal for development purposes as it enables some optimizations
while leaving debug checks enabled. cargo build --release Or: cargo build --profile opt-dev Then you can run the tests with the test.sh helper script: .github/workflows/test.sh -r target/release/dav1d Or: .github/workflows/test.sh -r target/opt-dev/dav1d The test script accepts additional arguments to configure how tests are run: -s PATH - Specify a path to the seek_stress binary in order to run the seek_stress tests. This is generally in the same output directory as the
main dav1d binary, e.g. target/release/seek_stress . -t MULTIPLIER - Specify a multiplier for the test timeout. Allows for tests
to take longer to run, e.g. if running tests with a debug build. -f DELAY - Specify a frame delay for the tests. If specified the tests will
also be run with multiple threads. -n - Test with negative strides. -w WRAPPER - Specify a wrapper binary to use to run the tests. This is
necessary for testing under QEMU for platforms other than the host platform. You can learn more about how to build and test by referencing the CI scripts in
the .github/workflows folder. Using rav1d librav1d is designed to be a drop-in replacement for libdav1d , so it
primarily exposes a C API with the same usage as libdav1d 's. This is found in
the librav1d.a library generated by cargo build . libdav1d 's primary API
documentation can be found
here for reference, and the
equivalent Rust functions can be found in src/lib.rs . You can
also reference the dav1d binary's code to see how it uses the API, which can
be found at tools/dav1d.rs . A Rust API is planned for
addition in the future.

======>
https://github.com/johannesvollmer/exrs/pull/241
-->>-->>
johannesvollmer / exrs Public Notifications You must be signed in to change notification settings Fork 24 Star 153 Code Issues 47 Pull requests 3 Discussions Actions Projects 0 Security Insights Additional navigation options Code Issues Pull requests Discussions Actions Projects Security Insights New issue Have a question about this project? Sign up for a free GitHub account to open an issue and contact its maintainers and the community. Sign up for GitHub By clicking “Sign up for GitHub”, you agree to our terms of service and privacy statement . We’ll occasionally send you account related emails. Already on GitHub? Sign in to your account Jump to bottom add rayon feature #241 Open oligamiq wants to merge 3 commits into johannesvollmer : master base: master Choose a base branch Branches Tags Could not load branches Branch not found: {{ refName }} Loading {{ refName }} default Could not load tags Nothing to show {{ refName }} default Loading Are you sure you want to change the base? Some commits from the old base branch may be removed from the timeline,
            and old review comments may become outdated. Loading Change base from oligamiq : master {"props":{"processingIndicatorUrl":"/johannesvollmer/exrs/pull/241/partials/processing_indicator","repositoryId":145625486,"pullRequestId":2119988821}} {"resolvedServerColorMode":"day"} Open add rayon feature #241 oligamiq wants to merge 3 commits into johannesvollmer : master from oligamiq : master +79 −16 Conversation 15 Commits 3 Checks 5 Files changed 6 Conversation This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters Show hidden characters Copy link oligamiq commented Oct 11, 2024 No description provided. Sorry, something went wrong. 1 sophie-h reacted with thumbs up emoji All reactions 1 reaction add rayon feature 2a7c5bf This was referenced Oct 11, 2024 Rayon should not be available as default feature image-rs/image#2028 Open Rayon should not be a default feature. #242 Open fintelia reviewed Oct 12, 2024 View reviewed changes Cargo.toml Outdated [package.metadata.docs.rs] all-features = true rustdoc-args = ["--cfg", "docsrs"] Copy link Contributor fintelia Oct 12, 2024 • edited Loading There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment This isn't needed anymore, since docs.rs recently added it as the default . Sorry, something went wrong. All reactions Copy link Contributor fintelia commented Oct 12, 2024 Not a maintainer, but FYI this is an API breaking change because any downstream code relying on the now cfg'd out methods will no longer compile. If rayon was left as a default feature, this change could be done in a backwards compatible way All reactions Sorry, something went wrong. Copy link Author oligamiq commented Oct 12, 2024 All the tests have passed, but indeed, this might be a breaking change. All reactions Sorry, something went wrong. Copy link Owner johannesvollmer commented Oct 13, 2024 Thanks for taking the time to contribute! The changed you proposed seem solid. I would have solved it differently, but I don't have the time to do that: As the calls to rayon are quite few and isolated, it should be possible to keep the API as-is. Then at runtime falling back to sequential processing if the rayon feature is disabled. This would require some more complicated code changed, but it would avoid us having to sprinkle cfg attributes in multiple unrelated code sections, which seems hard to maintain in my eyes (and is not backwards compatible). The backwards incompatible changes would require major version upgrade, exr 2.0 , which makes it harder for people to use the newest versions, as they have to manually update the version in their projects. What do you think? All reactions Sorry, something went wrong. Copy link Author oligamiq commented Oct 13, 2024 I think it’s possible to maintain all the public structs and APIs while marking them as deprecated and falling back. I'll be busy for a few days, but after that, I can give it a try if you'd like. All reactions Sorry, something went wrong. Copy link Owner johannesvollmer commented Oct 13, 2024 • edited Loading Checked the exr code and found something problematic, there is at least one public function that exposes a rayon item at compile time: pub fn new_with_thread_pool . Someone might rely on this function. As it references the rayon thread pool in the function type signature, it would no longer compile if rayon is removed. This means we cannot get around a breaking change. Please correct me if I'm wrong. Maybe it would be ok if the default is to enable rayon? Then the breaking change would be opt-in. All reactions Sorry, something went wrong. Copy link Author oligamiq commented Oct 15, 2024 That's right. I share the same opinion. While it's possible to replace the dependent types with generics, it would cause some significant breaking changes. In the case of removing Rayon from image-rs, it's acceptable to have Rayon set to default ON. However, setting Rayon to default ON is generally not advisable. All reactions Sorry, something went wrong. fintelia mentioned this pull request Oct 15, 2024 Fill in changelog and bump version for 0.25.3 image-rs/image#2347 Merged Copy link Author oligamiq commented Oct 16, 2024 Since there seem to be a lot of issues left, how about removing rayon from the default feature list at the time of a major version update? 1 dgsantana reacted with thumbs up emoji All reactions 1 reaction Sorry, something went wrong. Copy link Owner johannesvollmer commented Nov 3, 2024 after thinking about this, I'm happy to merge this. (of course we need to fix the 3 small conflicts, but that's not a big deal.) thanks for your contribution! All reactions Sorry, something went wrong. johannesvollmer reviewed Nov 3, 2024 View reviewed changes .github/workflows/rust.yml Show resolved Hide resolved johannesvollmer reviewed Nov 3, 2024 View reviewed changes Cargo.toml Outdated Show resolved Hide resolved Copy link Owner johannesvollmer commented Nov 3, 2024 • edited Loading @fintelia (edit:) I see that image-rs uses rayon, but only with a flag. I assume image will pass this flag to the exrs dependency? All reactions Sorry, something went wrong. Copy link Contributor fintelia commented Nov 3, 2024 Yes. After this lands, image will switch to only enabling the rayon feature on exr when its own rayon feature is enabled 1 johannesvollmer reacted with thumbs up emoji All reactions 1 reaction Sorry, something went wrong. Add rayon feature to default features in Cargo.toml 517cc5a oligamiq force-pushed the master branch
    from 2180a3f to 517cc5a Compare November 5, 2024 11:35 Resolve conflict 9b82d38 Copy link Author oligamiq commented Nov 5, 2024 I accepted the CI-related reviews and resolved the conflicts. All reactions Sorry, something went wrong. johannesvollmer approved these changes Nov 5, 2024 View reviewed changes Copy link Owner johannesvollmer left a comment There was a problem hiding this comment. Choose a reason for hiding this comment The reason will be displayed to describe this comment to others. Learn more . Choose a reason Spam Abuse Off Topic Outdated Duplicate Resolved Hide comment Thanks for taking the time for the follow up! I appreciate your contributions. Sorry, something went wrong. All reactions Sign up for free to join this conversation on GitHub .
    Already have an account? Sign in to comment Reviewers fintelia fintelia left review comments johannesvollmer johannesvollmer approved these changes Assignees No one assigned Labels None yet Projects None yet Milestone No milestone Development Successfully merging this pull request may close these issues. 3 participants Add this suggestion to a batch that can be applied as a single commit. This suggestion is invalid because no changes were made to the code. Suggestions cannot be applied while the pull request is closed. Suggestions cannot be applied while viewing a subset of changes. Only one suggestion per line can be applied in a batch. Add this suggestion to a batch that can be applied as a single commit. Applying suggestions on deleted lines is not supported. You must change the existing code in this line in order to create a valid suggestion. Outdated suggestions cannot be applied. This suggestion has been applied or marked resolved. Suggestions cannot be applied from pending reviews. Suggestions cannot be applied on multi-line comments. Suggestions cannot be applied while the pull request is queued to merge. Suggestion cannot be applied right now. Please check back later.
======>
https://github.com/awxkee
-->>-->>
Block or report awxkee Block user Prevent this user from interacting with your repositories and sending you notifications.
          Learn more about blocking users . You must be logged in to block users. Add an optional note: Please don't include any personal information such as legal names or email addresses. Maximum 100 characters, markdown supported. This note will be visible to only you. Block user Report abuse Contact GitHub support about this user’s behavior.
        Learn more about reporting abuse . Report abuse

======>
https://old.reddit.com/r/rust/comments/1gk1n4l/a_question_on_tokio_in_kubernetes/
-->>-->>
What's an appropriate setup for an i/o-bound rust application in kubernetes, using tokio?    

   Is the current_thread-scheduler always better if you're assigning less than 1vcpu (I'm thinking of assigning <100m), or are there other considerations to make?   

   If you know of good docs/books on the tonic, I'd love a recommendation   
   

======>
https://old.reddit.com/r/rust/comments/1gkhxmq/looking_for_a_good_ring_buffer_implementation/
-->>-->>
Maybe I should just use    mpsc    from    std   , but since I’m looking at single-producer use cases, I don’t know if I’m leaving performance on the table, but what I’d like to be able to do is essentially have one thread be able to do something like have one thread which does something like:   

   for x in 0..100 {
   sendChannel.send(x);
}
sendChannel.close();
   

   while another thread would do   

   while Some(x) = receiveChannel.receive() {
   println!("{x}");
}
   

   With the important notes that the    .send()    method will pause if the ring buffer is full and the    .receive()    method will pause if the ring buffer is empty and has not yet been closed.   

   I’d rather not implement this from scratch if someone else has already done it right. My basic idea is to be able to have a series of threads communicating to handle processing not unlike what happens if you do, e.g.,    

   cat foo | grep bar | sort
   

   where the individual processing steps are able to run independently. I find this sort of parallelism is much easier to reason about and get correct while enabling a program to maximize its use of multicore systems.   
   

======>
https://old.reddit.com/r/rust/comments/1gkd0bc/diffogus_a_diffing_crate/
-->>-->>
I made a    diffogus    crate that can show a difference between instances of a type.   

   For my project I needed a way to return a difference between 2 structs that hold various data types, I tried searching for existing crates but didn't fit my needs and probably unmaintained, so I made my own.   

   Currently it supports all primitive types (integers, floats and bools),    Option<T>   ,    HashMap<K, T>   ,    Vec<T>    where    T    implements required traits. You can also implement diffing for your struct, either with    Diff    derive macro (optional feature) or by hand.   

   You can also use    serde    feature to serialize diff results into desired format.   

   Currently crate is not zero-copy and uses    .clone()    in some places, for me this wasn't a big concern so I decided not to spend time implementing this before releasing. Also    Diff    macro only support structs with named fields right now, so for now you might need to implement diffing by hand, but I might add support for what's left later, or someone can make a PR and I'll review.   
   

======>
https://old.reddit.com/r/rust/comments/1gkjlkp/how_to_guess_what_to_do_for_speed_up_the_compile/
-->>-->>
I run    cargo build -p server --timings --release    and see my main 2 personal crates take ~90 % of the time.   

   I know, roughly, that if i split the code in more it could be faster, but which heuristic can be applied to avoid a massive refactor, and the not archieve much?   

   Note: This is for a    eCommerce    like app. I have most of the code split in modules per major sections:    Customer, Order, Invoice    etc.  All is inside the 2 major crates.   

   But there are a lot of inter-conected code, ie,    Customer    depends in like other 7 modules.   
   

======>
https://old.reddit.com/r/rust/comments/1gkc62c/doubt_on_deref_coercion/
-->>-->>
hey guys, I am pretty much new to rust. I have been reading Programming rust 2nd edition. So I am going through the below code snippet and I couldn't understand how the deref coercion working here   

   struct Selector<T> {

/// Elements available in this `Selector`.

elements: Vec<T>,


/// The index of the "current" element in `elements`. A `Selector`    /// behaves like a pointer to the current element.

current: usize
}
impl<T> Deref for Selector<T> {
    type Target = T;
    fn deref(&self) -> &T {
        &self.elements[self.current]
    }
}
impl<T> DerefMut for Selector<T> {
    fn deref_mut(&mut self) -> &mut T {
        &mut self.elements[self.current]
    }
}
fn main() {
    let s = Selector { elements: vec!["good", "bad", "ugly"],
        current: 2 };

    fn show_it(thing: &str) { println!("{}", thing); }
    show_it(&s);
}
   

   So in the above code snippet, s is of type Selector<&str>, so in the implementation deref trait  target T will be of type &str instead of str? and deref method gives &&str? Can you guys please help me understand how deref coersion working here?   

   Thanks!   
   

======>
https://old.reddit.com/r/rust/comments/1gkcfai/algorithms_for_efficiently_subtracting_constants/
-->>-->>
So I have this function that will run millions of times over the course of my program that will be used for computing colored light values in a voxel world. Playground:    https://play.rust-lang.org/?version=stable&mode=release&edition=2021&gist=76dcea1d1cc187ead7f4a779063a32f7        

   
pub fn sub_16(bytes: [u8; 4]) -> [u8; 4] {
    [
        bytes[0].saturating_sub(16),
        bytes[1].saturating_sub(16),
        bytes[2].saturating_sub(16),
        bytes[3].saturating_sub(16)
    ]
}
   
The problem is that the generated assembly is huge! Is there a better way of performing the same operation on a relatively small set of bytes like this?
   
playground::sub_16:
    movl%edi, %ecx
    shrl$8, %ecx
    movl%edi, %edx
    shrl$16, %edx
    movl%edi, %esi
    shrl$24, %esi
    xorl%r8d, %r8d
    subb$16, %dil
    movzbl%dil, %eax
    cmovbl%r8d, %eax
    subb$16, %cl
    movzbl%cl, %ecx
    cmovbl%r8d, %ecx
    subb$16, %dl
    movzbl%dl, %edx
    cmovbl%r8d, %edx
    subb$16, %sil
    movzbl%sil, %esi
    cmovbl%r8d, %esi
    shll$24, %esi
    movzbl%dl, %edx
    shll$16, %edx
    orl%esi, %edx
    movzbl%cl, %ecx
    shll$8, %ecx
    orl%edx, %ecx
    movzbl%al, %eax
    orl%ecx, %eax
    retq
   
   

======>
https://old.reddit.com/r/rust/comments/1gkacjh/asynchronous_rust_future_cannot_be_shared_between/
-->>-->>
I am using the rust redis library to perform some operation on a database.   

   I have a trait from an external library that I need to implement to my struct in order to read / write values the way I should from Redis.   

   Here is a simplified version of how the problematic function is defined :   

       /// Address space.
    type Address;

    /// Values space.
    type LocalValue;

    /// Memory error.
    type Error: Send + Sync + std::error::Error;


/// Address, LocalValue and Error are defined

/// Reads the words from the given addresses.
    fn read_from_db(
        &self,
        a: Vec<Self::Address>,
    ) -> impl Send + Sync + Future<Output = Result<Vec<Option<Self::LocalValue>>, Self::Error>>;
   

   When I implement this function like following :   

       async fn read_from_db(
        &self,
        addresses: Vec<Address>,
    ) -> Result<Vec<Option<Self::LocalValue>>, Self::Error> {

        let refs: Vec<&Address> = addresses.iter().collect();
        let value = self.clone().connection.mget::<_, Vec<_>>(&refs).await?;
        Ok(value)

    }    
   

   ```   

   I have the error :   

   error: future cann   ot be shared between threads safely   

   |
119 | / async fn batch_read(
120 | | &self,
121 | | addresses: Vec<Address>,
122 | | ) -> Result<Vec<Option<Self::LocalValue>>, Self::Error> {
| |_____________________________________________________^ future returned by \read_from_db` is not `Sync``
note: future is not \Sync` as it awaits another future which is not `Sync``
let value = self.clone().connection.mget::<_, Vec<_>>(&refs).await?;
| ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ await occurs here on type \Pin<Box<dyn Future<Output = Result<Vec<Option</* some type */>>, RedisError>> + Send>>`, which is not `Sync`
note: required by a bound in /* some trait */
|
70 | ) -> impl Send + Sync + Future<Output = Result<Vec<Option</* some type */>>, Self::Error>>;
| ^^^^ required by this bound in /* some trait */
   

   Thanks in advance ! I am really stuck in this   
   

======>
https://old.reddit.com/r/rust/comments/1gjunio/which_oss_software_would_you_like_to_see/
-->>-->>
I’m working on some code conversion tools at work and we’re looking for some real-world public code to demo with. Do you have a favorite non-Rust library or application you’d like to see rewritten in Rust as soon as possible?   
   

======>
https://old.reddit.com/r/rust/comments/1gk61ii/ot_everybodycodes_challenge_inspired_by_advent_of/
-->>-->>
Hello!   

   I would like to recommend you a cool challenge for programmers (of any language!) based on the Advent of Code idea -    Everybody.codes   . The challenge for programmers who want to solve algorithmic tasks has started today and will last for a total of 20 days.   

   The fun is great, in fact the tasks are very similar to AoC, with the same style and difficulty level. Instead of two parts, there are three each day - this is the main difference I noticed. The start/opening times of the tasks are different (versus AoC).   

   Other than that, it's not much different from AoC - and that's a good thing!   

   The website has more elaborate statistics and leaderboard, other than that you will feel at home if you have used AoC.   

   It is worth participating, especially as the EC is a month before the AoC, so it can serve as a preparation, a warm-up before the AoC!   

   I hope some of you will join in!   

   https://everybody.codes/event/2024/       
   

======>
https://the-mikedavis.github.io/posts/german-string-optimizations-in-spellbook
-->>-->>
the-mikedavis /about /posts | updateItemToggleTheme() "German string" optimizations in Spellbook . Posted on 2024-11-03 :: Tags: Rust , optimization :: Source Code Table of Contents Spellbook Strings in Spellbook Strings in Rust Box<str> and fat pointers The road to "German strings" Memory savings Theory into practice: let's build UmbraString Default Allocating Instantiation Reconstructing a byte slice Clone Drop Eq Benchmarking and memory analysis Bonus points: the FlagSet can also be German! Pitfalls and MaybeUninit<T> Zeroed bit patterns Null pointer optimization and strange behavior FlagSlice Memory Savings Wrapping up & Kudos Spellbook Spellbook is a Rust spell-checking library I've written the style of Hunspell to bring spell checking to the Helix editor . It's more-or-less a Rust rewrite of Nuspell , which itself is more-or-less a rewrite of Hunspell. Spellbook has a pretty slim interface: you can instantiate a dictionary from Hunspell dictionary files and use it to check words. For a small example of how you might use Spellbook: fn main () { // Dictionary files can be sourced from // <https://github.com/LibreOffice/dictionaries> let aff = std::fs::read_to_string(" en_US.aff "). unwrap (); let dic = std::fs::read_to_string(" en_US.dic "). unwrap (); let dict = spellbook::Dictionary::new(&aff, &dic). unwrap (); let word = std::env::args(). nth ( 1 ). expect (" expected a word to check "); if dict. check (&word) { println!(" {word:?} is in the dictionary. "); } else { println!(" {word:?} is NOT in the dictionary. "); std::process::exit( 1 ); } } RUST In this post we'll be looking at the string representation used in Spellbook and aiming to optimize it to save memory. Strings in Spellbook How Spellbook works exactly is beyond the scope of this post, so this section gives a simplified overview and deals with simplified types. If you're interested in more details, check out the Spellbook README or @zverok's Rebuilding the Spellchecker blog post and the Spellbook internals document . A central part of the procedure to check a word is to look up word(s) in a hash table. This lookup table contains an entry for each "stem" in the dictionary. You might imagine that the Dictionary type is a wrapper around a HashSet<String> . This is correct in essence but Hunspell-like checkers don't store every possible word in memory. Instead there is some "compression." For an example from the en_US (American English) dictionary, the lookup table in Spellbook associates a stem "adventure" with a set of flags like 'D', 'R' and 'S'. The flags correspond to rules defined for the dictionary allowing transformations like prefixes and suffixes. 'D' for example allows adding the "d" (or "ed" or "ied", depending on the stem) suffix, producing "adventured." 'R' allows "adventurer" and 'S' allows "adventures." So we can imagine that the lookup table has a type similar to HashMap<String, HashSet<Flag>> . Despite the "compression" that prefixes and suffixes enable, the lookup table contains many entries. The exact number varies with which dictionary files you use as input but American English contains around 50,000 stems, and it's a relatively slim dictionary. Others contain hundreds of thousands or even millions of stems, so it's worth trying to optimize the space we take for each stem. Good optimizations come from good observations so let's list out some properties of these strings: Once inserted into the lookup table these strings are never modified. These strings have a small maximum size. Spellbook refuses to check words over 360 bytes long (in UTF-8 representation) so there's no point in storing words over 360 bytes in the lookup table. Stems correspond to words so they're typically shorter rather than longer. Strings in Rust Let's take a bit of a detour to talk about how strings are represented in Rust. For starters there's the String type. String s are quite flexible: they can be modified, resized and have a large maximum size. As for how they are represented, the Rust docs say: A String is made up of three components: a pointer to some bytes, a length, and a capacity. Simplifying a bit here, we can imagine a String looks like this: struct String { pointer : NonNull< u8 >, length : usize , capacity : usize , } RUST Box<str> and fat pointers The first thing that comes to mind is that storing length and capacity is redundant for our use-case. In our lookup table the strings are never modified so there's no need to store any extra information that would allow us to resize the string. A non-resizable string can be written with the Box<str> type. Box<str> is the owned version of a &str . &str and slices ( &[T] ) have an interesting representation and learning about them is a good way to dig into "fat pointers" in Rust. A &str (or equivalently, &[u8] ) is a fat pointer - a pointer to some bytes plus some metadata. For &[T] the metadata is the length of the slice. Using a fat pointer makes string ( &str ) and other slices nice to work with - you can subslice and read the length of a string slice cheaply and ergonomically. Box<str> and Box<[T]> are laid out the same way. You can imagine that these fat pointers are basically a tuple (*const T, usize) . This takes 2 usize s worth of memory to represent: one usize for the actual pointer ("thin pointer") and one for the metadata. What exactly is a usize though? Quoting the Rust docs again: The size of [ usize ] is how many bytes it takes to reference any location in memory. For example, on a 32 bit target, this is 4 bytes and on a 64 bit target, this is 8 bytes. So usize is an unsigned integer type of the same size as a "thin pointer": a pointer with no metadata, like *const T / *mut T or equivalently NonNull<T> . For simplicity we'll talk only about 64 bit targets for the rest of the post and assume that size_of::<usize>() == 8 . By switching the stem type to Box<str> we save 8 bytes per stem from not tracking capacity , taking advantage of our observation that strings are not modified. Nice! But there's still room for improvement from our other observations. The road to "German strings" The other observations are about the length of each string. They're short. If the length field is a usize that means your strings can be at most 2^64 bytes long, and wow that is long ! Our strings will never be longer than 360 bytes so of the 64 bits we use to represent the length we'll only ever use 9 (2^9 = 512). That's quite a few bits wasted. If we used a u16 to store the length instead we'd save 6 bytes. What should we do with those 6 bytes we've saved? This is where "German strings" come in. "German strings" or "German-style strings" or "Umbra strings" (all the same thing) are described very well in a post from CedarDB: Why German Strings are Everywhere . The idea is to use a integer type smaller than usize for the length ( u32 in their case) and repurpose the remaining bytes to store a prefix of the data. We can store a few more bytes in the "prefix" section since we're using a u16 for length, so our type would look like this in memory: #[ repr (C)] struct UmbraString { len : u16 , // takes 2 bytes prefix : [ u8 ; 6], // takes 6 bytes pointer : NonNull< u8 >, // this takes `usize` (8 bytes) } RUST +-------+-----------------------+-------------------------------+ +  len  +        prefix         +           pointer             + +-------+-----------------------+-------------------------------+ u16           6x u8                       8x u8 DEFAULT Umbra and CedarDB like this prefix because it can be used to cheaply compute whether two of these UmbraString s are (not) equal - the Eq trait in Rust. Consider a very short string like "hi!". In memory that would look like so: +-------+-----------------------+-------------------------------+ + 3u16  + h   i   !   .   .   . +         pointer (?)           + +-------+-----------------------+-------------------------------+ DEFAULT And what's the pointer pointing to? Nothing I guess. We already stored the full string right in the struct "inline." So there's no need to allocate memory and point to it. In fact for medium-long strings that can fit in the prefix bytes plus the pointer bytes, we can eliminate the pointer part altogether. This is a S hort S tring O ptimization (SSO): when the string is short enough, we can store it directly in our UmbraString struct and avoid allocating a buffer. We can store 6 bytes in the prefix and another 8 in the suffix area for a total of 14 bytes inline. For an ASCII string, that's up to 14 characters we can represent without allocating. Very nice! +-------+-----------------------+-------------------------------+ + 12u16 + h   e   l   l   o  _  + w   o   r   l   d   !   .   . + +-------+-----------------------+-------------------------------+ len           prefix                     suffix DEFAULT This either-or type would look like so, using a union : #[ repr (C)] struct UmbraString { len : u16 , prefix : [ u8 ; 6], trailing : Trailing } #[ repr (C)] union Trailing { suffix: [ u8 ; 8 ], // ManuallyDrop is necessary since we only want // to deallocate the buffer if we're using the // "long" variant of this union. ptr: ManuallyDrop<NonNull< u8 >>, } RUST How do we know which member of the union our UmbraString is? Just look at the len field: if it's 14 or less then we're using the "short" variant - everything inline. If it's 15 or greater then the string is allocated and pointed to. Memory savings Why is this layout so attractive? This representation is no more expensive than a Box<str> in terms of memory consumption. size_of::<Box<str>>() is 16 - 16 bytes. (Note that size_of is counting the size of the type, not the size of the allocation the pointer is pointing to.) size_of::<UmbraString>() is also 16 . The difference is that any non-empty Box<str> will allocate. A short string like "hi!" allocates 3 bytes somewhere on the heap for a total of 19 bytes. UmbraString does not: it's still 16 bytes. For a medium string like "hello_world!" Box<str> will allocate those 12 bytes on the heap for a total cost of 28 bytes. The equivalent UmbraString is still a total of 16 bytes. For long strings like "a".repeat(50) , Box<str> will allocate the 50 bytes for a total cost of 66 bytes. In the worst case (long strings) UmbraString is no worse : it also takes exactly 66 bytes. Umbra strings are attractive here because they don't have a memory cost: we would be paying the 16 bytes of a Box<str> anyways and wasting the 6 bytes from the length usize . Any time we use the inline variant of UmbraString we save memory. You might also think UmbraString is faster to work with if you commonly have short strings because you don't need to follow a pointer to compare data. We'll see in the benchmarks that UmbraString is not much different in terms of speed. We need an extra comparison operation to figure out if we're using a short or long variant after all. Theory into practice: let's build UmbraString This is basically the same snippet as above. We'll define some constants for the lengths of each segment and some basic helpers. use core::mem::{size_of, ManuallyDrop}; use core::ptr::NonNull; // 6 on 64 bit machines const PREFIX_LEN : usize = size_of::< usize >() - size_of::< u16 >(); // 8 on 64 bit machines const SUFFIX_LEN : usize = size_of::< usize >(); // We can fit 14 bytes inline, nice! const INLINE_LEN : u16 = ( PREFIX_LEN + SUFFIX_LEN ) as u16 ; #[ repr (C)] pub struct UmbraString { len : u16 , prefix : [ u8 ; PREFIX_LEN], trailing : Trailing, } #[ repr (C)] union Trailing { suffix: [ u8 ; SUFFIX_LEN ], ptr: ManuallyDrop<NonNull< u8 >>, } impl UmbraString { pub fn len (& self ) -> usize { self .len as usize } pub fn is_empty (& self ) -> bool { self .len == 0 } } RUST Default The empty string is easy to represent: the length is 0 so it belongs as the inline variant. We'll set everything to zero - we won't access those bytes so it doesn't really matter what they're set to, but this seems like a reasonable default. impl Default for UmbraString { fn default () -> Self { Self { len: 0 , prefix: [ 0 ; PREFIX_LEN ], trailing: Trailing { suffix: [ 0 ; SUFFIX_LEN ] } } } } RUST Allocating Let's define some helper functions for actually allocating the data. The allocation helpers are only used when working with the long variant. A &str is a &[u8] that is valid UTF-8 so we'll be working in terms of *mut u8 / *const u8 thin pointers. use alloc::alloc; use core::ptr::{ self , NonNull}; fn copy_slice ( src : &[ u8 ]) -> NonNull< u8 > { let layout = layout (src. len ()); let nullable = unsafe { alloc::alloc(layout) }; let ptr = match NonNull::new(nullable) { Some(ptr) => ptr. cast (), None => alloc::handle_alloc_error(layout), }; unsafe { ptr::copy_nonoverlapping(src. as_ptr (), ptr. as_ptr (), source. len ()); } ptr } fn layout ( len : usize ) -> alloc::Layout { alloc::Layout::array::< u8 >(len) . expect (" a valid layout for an array ") . pad_to_align () } RUST copy_slice allocates an array of bytes on the heap and then copies the source byte slice into our new array, and returns the pointer. Instantiation To create an UmbraString we'll take an existing &str as input. This operation could possibly fail if the input string is too long. Let's ignore that for now and just assert! that the string is not too long: impl From< str > for UmbraString { fn from ( src : &src) -> Self { assert!(src. len () <= u16 :: MAX as usize ); let len = src. len (); let mut prefix = [ 0 ; PREFIX_LEN ]; let trailing = if len as u16 <= INLINE_LEN { let suffix = [ 0 ; SUFFIX_LEN ]; if len <= PREFIX_LEN { prefix[..len]. copy_from_slice (source); } else { prefix. copy_from_slice (&source[.. PREFIX_LEN ]); suffix[..len - PREFIX_LEN ]. copy_from_slice (&source[ PREFIX_LEN ..]); } Trailing { suffix } } else { let ptr = copy_slice (source); Trailing { ptr: ManuallyDrop::new(ptr) } } Self { len: len as u16 , prefix, trailing } } } RUST For the short variant ( src.len() as u16 <= INLINE_LEN ) we copy from the source byte slice into however much of the prefix and suffix slices we can fill and leave the rest as 0 s. (Note that 0 is a valid representation in UTF-8. See the section below on FlagSet s for more discussion on why this is important.) For the long variant we'll use our copy_slice helper from above to allocate a new byte array pointer. Reconstructing a byte slice Did you notice in our copy_slice helper function above that we copy the entire slice into a newly allocated array buffer instead of the part after the prefix? We copied source instead of &source[PREFIX_LEN..] . You might think that we could save some space by only storing the remaining bytes after the prefix - and we could - but that would prevent us from recreating a &[u8] or &str from an UmbraString . Slices are contiguous memory chunks - array layouts in memory. We can't create a slice that starts in the prefix field and then continues by following a pointer. All of the data needs to be in one place. With that in mind, let's add a function to get our bytes back: use core::{ptr, slice}; impl UmbraString { pub fn as_slice (& self ) -> &[ u8 ] { let ptr = if self .len <= INLINE_LEN { let ptr = ptr::from_ref( self ); unsafe { ptr::addr_of!((*ptr).prefix) }. cast () } else { unsafe { self .trailing.ptr }. as_ptr () }; unsafe { slice::from_raw_parts(ptr, self . len ()) } } pub fn as_bytes (& self ) -> &[ u8 ] { self . as_slice () } pub fn as_str (& self ) -> & str { unsafe { core::str::from_utf8_unchecked( self . as_slice ()) } } } RUST For inline Umbra strings our slice starts at the prefix field and ends either in the prefix field's array or in the suffix field's array depending on the length. The #[repr(C)] annotation on UmbraString and Trailing enforces that when represented in memory at runtime, the fields are in the same order as we define them, so we can safely assume that prefix comes before suffix and there's no space between. We can safely treat them as contiguous memory. For allocated strings we reconstruct the slice directly from our allocated buffer's pointer. Remember earlier when we said that slices were basically (*const T, usize) ? That's what we give to slice::from_raw_parts - a pointer to an array layout in memory and a length - and we get a fat pointer. Clone Cloning the string is similar to how we initially created one from a &str . impl Clone for UmbraString { fn clone (& self ) -> Self { let trailing = if self .len <= INLINE_LEN { let suffix = unsafe { self .trailing.suffix }; Trailing { suffix } } else { let ptr = copy_slice ( self . as_slice ()); Trailing { ptr: ManuallyDrop::new(ptr) } }; Self { len: self .len, prefix: self .prefix, trailing, } } } RUST The len and prefix fields are copied. For the inline version we copy the suffix array too, and for the allocated version we create a new allocation and copy self 's buffer. Another nice property of this type you might notice here: for strings short enough to be inlined, Clone is actually a Copy - no allocation required. Drop Now on to Drop . We need to deallocate our allocated buffer for the long variant. For the short variant we do nothing: Copy types are cleaned up without any mention in Drop . impl Drop for UmbraString { fn drop (& self ) { if self .len > INLINE_LEN { let layout = layout ( self . len ()); let ptr = unsafe { self .trailing.ptr }. as_ptr (); unsafe { alloc::dealloc(ptr. cast (), layout); } } } RUST Eq As the CedarDB article notes, we can optimize the comparison of Umbra strings. To do that we cast the len and prefix chunks together as a usize and compare those, and then compare the remaining parts of the string if that first word of memory is equal. We don't use the Eq optimization in Spellbook since Umbra strings are only used for the lookup table representation (we use PartialEq<str> for UmbraString instead), but it's interesting from an academic perspective. impl PartialEq< Self > for UmbraString { fn eq (& self , other : & Self ) -> bool { let self_len_and_prefix = ptr::from_ref( self ).cast::< usize >(); let other_len_and_prefix = ptr::from_ref(other).cast::< usize >(); if unsafe { *self_len_and_prefix != *other_len_and_prefix } { return false ; } // The lengths and prefixes are equal. Now compare the rest. if self .len <= INLINE_LEN { // We can use the same trick as above: compare the suffixes as one big chunk. let self_ptr = ptr::from_ref( self ); let self_suffix = unsafe { ptr::addr_of!((*self_ptr).trailing.suffix) }.cast::< usize >(); let other_ptr = ptr::from_ref(other); let other_suffix = unsafe { ptr::addr_of!((*other_ptr).trailing.suffix) }.cast::< usize >(); unsafe { *self_suffix == *other_suffix } } else { let suffix_len = self . len () - PREFIX_LEN ; let self_rest = unsafe { slice::from_raw_parts( self .trailing.ptr. as_ptr (). add ( PREFIX_LEN ), suffix_len ) }; let other_rest = unsafe { slice::from_raw_parts( other.trailing.ptr. as_ptr (). add ( PREFIX_LEN ), suffix_len ) }; self_rest == other_rest } } } impl Eq for UmbraString {} RUST We start by comparing the length and prefix parts together with one usize comparison. If that is equal then we need to check the rest. For the short variant we can use another usize comparison to check the rest. For the long variant we can reconstruct the byte slices for the remaining bytes and compare those. We can actually make this a little better. We know in that else block that the lengths of self and other are equal but comparing the byte slices ( PartialEq<Self> for &[T] ) will repeat that check. We can skip that check and do the comparison directly. Since u8 s are byte-wise equal to each other, we can use memcmp like the standard library does. impl PartialEq< Self > for UmbraString { fn eq (& self , other : & Self ) -> bool { // ... unchanged ... if self .len <= INLINE_LEN { // ... unchanged ... } else { let suffix_n_bytes = self . len () - PREFIX_LEN ; unsafe { memcmp ( self .trailing.ptr. as_ptr (). add ( PREFIX_LEN ), other.trailing.ptr. as_ptr (). add ( PREFIX_LEN ), suffix_n_bytes, ) == 0 } } } } // Snipped from `library/core/src/slice/cmp.rs`: extern " C " { /// Calls implementation provided memcmp. /// /// Interprets the data as u8. /// /// Returns 0 for equal, < 0 for less than and > 0 for greater /// than. fn memcmp ( s1 : *const u8 , s2 : *const u8 , n : usize ) -> core::ffi::c_int; } RUST Benchmarking and memory analysis Speed benchmarks are unfortunately not very interesting. Spellbook doesn't take advantage of the Eq comparison so we only end up paying for the conversion in UmbraString::as_slice . This is nearly imperceptibly slower than Box<str>::as_bytes . Using cargo bench and simple benchmarks like so: // NOTE: this needs nightly. #![ feature (test)] extern crate test; use test::{black_box, Bencher}; use spellbook::umbra_slice::UmbraString; #[ bench ] fn umbra_str_as_bytes ( b : & mut Bencher) { let s: UmbraString = " a ". repeat ( 50 ). into (); b. iter (|| black_box (&s). as_bytes ()); } #[ bench ] fn boxed_str_as_bytes ( b : & mut Bencher) { let s: Box< str > = " a ". repeat ( 50 ). into (); b. iter (|| black_box (&s). as_bytes ()); } RUST umbra_str_as_bytes measures at around 0.69 ns/iter on my machine while boxed_str_as_bytes measures around 0.46 ns/iter. We would need to be converting to bytes very very often to notice the difference, and Spellbook doesn't ultimately convert that often. The benchmarks for Spellbook's check function don't change perceptibly. Where we see the difference is in memory usage and heap interaction. Measuring heap allocations is not as straightforward in Rust as you might imagine if you're coming from garbage collected languages: garbage collectors need to track the heap to know when to clean up garbage so there's typically an interface to query heap information. Not so with Rust. Measuring Memory Usage in Rust from the rust-analyzer blog points out a few options. Of them I'm partial to valgrind 's DHAT tool since it's straightforward to use. We'll run a small example program that creates the en_US dictionary and checks a single word: cargo run --release --example check hello valgrind --tool =dhat ./target/release/examples/check hello SH Before ( Box<str> stems), DHAT reports: Total:     3,086,190 bytes in 130,988 blocks At t-gmax: 2,717,005 bytes in 90,410 blocks At t-end:  0 bytes in 0 blocks Reads:     3,923,475 bytes Writes:    2,610,900 bytes DEFAULT After ( UmbraString stems): Total:     2,714,546 bytes in 82,475 blocks At t-gmax: 2,343,567 bytes in 41,487 blocks At t-end:  0 bytes in 0 blocks Reads:     2,332,587 bytes Writes:    2,239,256 bytes DEFAULT We've saved around 300kb of total runtime memory (12%) with the change, plus we're using fewer blocks of memory and reading from and writing to the heap less. Success! We can go further though if we apply this "German string" optimization to another oft-instantiated type in the lookup table: the FlagSet . Bonus points: the FlagSet can also be German! Remember way back at the beginning of the post when were discussing the lookup table and how it's like a HashMap<String, HashSet<Flag>> ? The HashSet<Flag> part is defined in the Spellbook source as a FlagSet newtype wrapper. It doesn't wrap a HashSet<Flag> though - hash sets can be wasteful in terms of memory usage. Before the Umbra string optimization they were represented as Box<[Flag]> . For short slices, slice::contains or slice::binary_search are very fast at determining set membership. Like stems, flagsets are usually short. If we measure a histogram of the number of flags used per stem in all dictionaries in LibreOffice/dictionaries , we see the distribution skew very short: Number of flags Percentile (rounded) 0 32 1 69 2 80 3 86 4 90 ... ... 7 96 ... ... One crazy dictionary used 271 flags on a single stem. So if we can store some number of flags inline like we did with bytes an Umbra string, we can avoid allocations in the vast majority of cases. Rather than an "Umbra string" we'll be constructing a more generic "Umbra slice" type. In fact we can imagine that the UmbraString is just a special case of an UmbraSlice around bytes: // These bytes are valid UTF-8. struct UmbraString(UmbraSlice< u8 >); RUST The new type comes with new challenges though. For... reasons ... Flag is defined as: type Flag = core::num::NonZeroU16; RUST So rather than dealing with bytes we need to deal with 16-bit integers. Ok, that changes the arithmetic a little: // We can fit 3 u16s in the prefix. const fn prefix_len <T>() -> usize { // Remove 16 bits for the `len`. (size_of::< usize >() - size_of::< u16 >()) / size_of::<T>() } // And 4 in the suffix. const fn suffix_len <T>() -> usize { size_of::< usize >() / size_of::<T>() } RUST We can fit up to 7 flags inline. That's really awesome: it'll cover up to 96% of real-world flagsets and should save us many many really tiny allocations. Pitfalls and MaybeUninit<T> We're talking in terms of u16 above but our type is actually a NonZeroU16 . They have the same size and layout but NonZeroU16 can't be 0u16 . The challenge is the NonZero nature: the zeroed bit pattern is not a valid representation, and Default for NonZeroU16 is not a thing. Places where we wrote [0u8; N] above have to be rewritten anyways since we're changing the type, but we can't just say: // 💣 UNDEFINED BEHAVIOR!! let mut prefix: [T; PREFIX_LEN ] = unsafe { core::mem::zeroed() }; let mut suffix: [T; SUFFIX_LEN ] = unsafe { core::mem::zeroed() }; RUST You can't say that a value is a NonZeroU16 and at the same time represent it with zeroes, even if you never formally access those elements of the array. The proper way to encode what we're trying to do is to use MaybeUninit . use core::mem::MaybeUninit; use crate ::Flag; // Unfortunately we cannot call `prefix_len`/`suffix_len` within // the definition of `UmbraSlice` so we need to use const generics. // The result is that this type is not pretty :/ pub type FlagSlice = UmbraSlice< Flag, { prefix_len::<Flag>() }, { suffix_len::<Flag>() }, >; #[ repr (C)] pub struct UmbraSlice<T: Copy, const PREFIX_LEN: usize , const SUFFIX_LEN: usize > { len : u16 , prefix : [MaybeUninit<T>; PREFIX_LEN], trailing : Trailing<T, SUFFIX_LEN>, } #[ repr (C)] union Trailing<T: Copy>, const SUFFIX_LEN : usize > { suffix: [MaybeUninit<T>; SUFFIX_LEN ], ptr: ManuallyDrop<NonNull<T>>, } impl <T: Copy, const PREFIX_LEN: usize , const SUFFIX_LEN: usize > UmbraSlice<T, PREFIX_LEN, SUFFIX_LEN> { const INLINE_LEN : u16 = ( PREFIX_LEN + SUFFIX_LEN ) as u16 ; } RUST This makes the type slightly harder to work with: when accessing the prefix and suffix arrays we need to be sure to ptr::cast() from a pointer of MaybeUninit<T> to a pointer of T . When initializing the slice in our From implementation we need to transmute the source slice from &[T] to &[MaybeUninit<T>] before we can copy the data: fn copy_to_slice <T: Copy>( dst : & mut [MaybeUninit<T>], src : &[T]) { // SAFETY: &[T] and &[MaybeUninit<T>] have the same layout. let uninit_src: &[MaybeUninit<T>] = unsafe { core::mem::transmute(src) }; dst. copy_from_slice (uninit_src); } RUST Zeroed bit patterns We also need to be very careful to initialize prefix and suffix with MaybeUninit<T>::zeroed() rather than MaybeUninit<T>::uninit() . Why? Remember that our PartialEq<Self> implementation compares the prefix array and maybe also the suffix array for the short variant. Those arrays might contain uninitialized data if the length of the slice is shorter than the INLINE_LEN or PREFIX_LEN . MaybeUninit<T>::zeroed() works around this because comparing zeroed bits is defined behavior. The important distinction is that we are not treating the zeroed memory as NonZeroU16 . That is undefined behavior. If we treat it as a usize though, the zeroed bit pattern is valid and the behavior is defined. It's also accurate as long as T is Copy . // Note that `T` is not bound by `Eq`. // We only ever compare bits, not `T`s. impl <T: Copy, const PREFIX_LEN: usize , const SUFFIX_LEN: usize > PartialEq< Self > for UmbraSlice<T, PREFIX_LEN, SUFFIX_LEN> { fn eq (& self , other : & Self ) -> bool { // SAFETY: the `prefix` field is created with `MaybeUninit::zeroed` memory, so even // if the slice has fewer than `PREFIX_LEN` elements, comparing the uninitialized // memory is defined behavior, and it is accurate since `T` is `Copy`. let self_len_and_prefix = ptr::from_ref( self ).cast::< usize >(); let other_len_and_prefix = ptr::from_ref(other).cast::< usize >(); if unsafe { *self_len_and_prefix != *other_len_and_prefix } { return false ; } // ... compare suffixes ... } } RUST Null pointer optimization and strange behavior What exactly can go wrong if you don't use MaybeUninit<T> ? The compiler can see that NonZeroU16 cannot ever be a zeroed bit pattern and it can design the layouts for other types using FlagSlice around that. If we designed our type like this: #[ repr (C)] struct FlagSlice { len : u16 , prefix : [Flag; PREFIX_LEN], trailing : Trailing, } #[ repr (C)] union Trailing { suffix: [Flag; SUFFIX_LEN ], ptr: ManuallyDrop<NonNull<Flag>>, } RUST Then FlagSlice is eligible for the null pointer memory layout optimization . The compiler can tell that the zero bit pattern is not a valid representation for the struct and so it can try to fit other information in that representation, like whether an Option<T> is Some or None . It's a really handy optimization that makes size_of::<Option<T>>() == size_of::<T>() - you don't pay for the option. But how would you represent the empty flag slice? // 💣 UNDEFINED BEHAVIOR!! impl Default for FlagSlice { fn default () -> Self { Self { len: 0 , prefix: unsafe { core::mem::zeroed() }, trailing: Trailing { suffix: unsafe { core::mem::zeroed() }, } } } } RUST The length is zero, the prefix is zeroes, the suffix is zeroes. The whole struct is zeroes! With this representation, Option::<FlagSlice>::None is exactly the same as FlagSlice::default() , causing your code to behave weirdly . Suddenly Some(FlagSlice::default()).is_some() is false ! 🥴 While this pitfall seems scary and hard to debug, Miri has got your back. Write types without the MaybeUninit<T> wrapper and cargo miri test will helpfully point out that you're opening yourself up to undefined behavior. FlagSlice Memory Savings Rerunning the same example from above, DHAT reports: Total:     2,584,850 bytes in 44,741 blocks At t-gmax: 2,190,833 bytes in 947 blocks At t-end:  0 bytes in 0 blocks Reads:     1,733,361 bytes Writes:    2,109,560 bytes DEFAULT So to compare: Stem + FlagSet Total At t-gmax Reads (B) Writes (B) Box<str> + Box<[Flag]> 3,086,190 bytes in 130,988 blocks 2,717,005 bytes in 90,410 blocks 3,923,475 2,610,900 UmbraString + Box<[Flag]> 2,714,546 bytes in 82,475 blocks 2,343,567 bytes in 41,487 blocks 2,332,587 2,239,256 UmbraString + FlagSlice 2,584,850 bytes in 44,741 blocks 2,190,833 bytes in 947 blocks 1,733,361 2,109,560 These are some respectable savings! We've cut out about a half of a megabyte of total memory, used far fewer allocations (blocks) and write to the heap a fair amount less. Plus we read from the heap less than half as much as we did before the changes. Not every dictionary will see the same savings, though: some dictionaries use more flags and have longer stems. But as discussed above, every time we use a short variant of an Umbra slice we save memory over a Box<str> or Box<[Flag]> . Wrapping up & Kudos We've designed and implemented a German string inspired UmbraSlice<T> type that can carry a small number of T s inline - a small slice optimization - and used it to save a respectable amount of total memory for the Dictionary type, and also cut way down on heap interaction. We've also stumbled upon lots of interesting detours into Rust topics: fat pointers, runtime memory measurement, MaybeUninit<T> and the null-pointer optimization. The full code for UmbraSlice<T> lives in Spellbook's repository in src/umbra_slice.rs . As mentioned above, CedarDB has an excellent intro post for German strings and also a nice deeper dive . The former has a snide remark about an optimization which is supposedly impossible in Rust, provoking interesting response posts by those who had been successfully nerd-sniped. One of these - An Optimization That's Impossible in Rust! - I found very informative on the Rust aspects of implementing German strings, and may be interesting if your use-case benefits from Clone for UmbraString being cheap like Clone for Arc . (Not so for Spellbook.) Thank you to these authors!
======>
https://old.reddit.com/r/rust/comments/1gk8fk9/how_to_create_a_3dterminal_renderer_using_rust/
-->>-->>
Recently I posted here about a game    Felicia    and I made called    TermTrack   . It gained some traction and some people were wondering how to go about creating something like it. So I made a blog post about creating a simplified 3D-renderer for the terminal as a starting point! Check it out :)   

   Blog post:    https://tagedan.github.io/posts/terminal_rendering.html   
   

======>
https://old.reddit.com/r/rust/comments/1gk3v7i/image_v0255_brings_much_improved_avif_decoding/
-->>-->>
image    is the #1 image processing crate.   

   The latest release brings many improvements to AVIF decoding    contributed    by    @awxkee   . 10-bit and 12-bit AVIF images are now supported, and many bugs in AVIF decoding have been fixed.   

   Also, the    rayon    feature now correctly toggles the use of parallelism in AVIF encoding. The only remaining format where parallelism isn't toggled correctly is EXR, because that would be a    semver-breaking change    for the    exr    the crate.   

   Finally,    .jfif    is now recognized as a JPEG file extension. It is valid but very rarely used, which is why it took us until now to add it.   

   Note that AVIF decoding still depends on the C library    dav1d    rather than the Rust port of it,    rav1d   . This is because    rav1d    does not expose a Rust API, not even through a crate that wraps the    dav1d    C API. We hope that this will change in the future, and we will be able to migrate away from    dav1d    which is our last remaining C dependency.   
   

======>
https://smallcultfollowing.com/babysteps/blog/2024/11/05/minpin/
-->>-->>
MinPin: yet another pin proposal 5 November 2024 NB. This page is part of the series "Overwrite trait" . Click here to see all posts . This post floats a variation of boats’ UnpinCell proposal that I’m calling MinPin . 1 MinPin’s goal is to integrate Pin into the language in a “minimally disruptive” way 2 – and in particular a way that is fully backwards compatible. Unlike Overwrite , MinPin does not attempt to make Pin and &mut “play nicely” together. It does however leave the door open to add Overwrite in the future, and I think helps to clarify the positives and negatives that Overwrite would bring. TL;DR: Key design decisions Here is a brief summary of MinPin’s rules The pinned keyword can be used to get pinned variations of things: In types, pinned P is equivalent to Pin<P> , so pinned &mut T and pinned Box<T> are equivalent to Pin<&mut T> and Pin<Box<T>> respectively. In function signatures, pinned &mut self can be used instead of self: Pin<&mut Self> . In expressions, pinned &mut $place is used to get a pinned &mut that refers to the value in $place . The Drop trait is modified to have fn drop(pinned &mut self) instead of fn drop(&mut self) . However, impls of Drop are still permitted (even encouraged!) to use fn drop(&mut self) , but it means that your type will not be able to use (safe) pin-projection. For many types that is not an issue; for futures or other “address sensitive” types, you should use fn drop(pinned &mut self) . The rules for field projection from a s: pinned &mut S reference are based on whether or not Unpin is implemented: Projection is always allowed for fields whose type implements Unpin . For fields whose types are not known to implement Unpin : If the struct S is Unpin , &mut projection is allowed but not pinned &mut . If the struct S is !Unpin [^neg] and does not have a fn drop(&mut self) method, pinned &mut projection is allowed but not &mut . If the type checker does not know whether S is Unpin or not, or if the type S has a Drop impl with fn drop(&mut self) , neither form of projection is allowed for fields that are not Unpin . There is a type struct Unpinnable<T> { value: T } that always implements Unpin . Design axioms Before I go further I want to layout some of my design axioms (beliefs that motivate and justify my design). Pin is part of the Rust language. Despite Pin being entirely a “library-based” abstraction at present, it is very much a part of the language semantics, and it deserves first-class support. It should be possible to create pinned references and do pin projections in safe Rust. Pin is its own world. Pin is only relevant in specific use cases, like futures or in-place linked lists. Pin should have zero-conceptual-cost. Unless you are writing a Pin -using abstraction, you shouldn’t have to know or think about pin at all. Explicit is possible. Automatic operations are nice but it should always be possible to write operations explicitly when needed. Backwards compatible. Existing code should continue to compile and work. Frequently asked questions For the rest of the post I’m just going to go into FAQ mode. I see the rules, but can you summarize how MinPin would feel to use ? Yes. I think the rule of thumb would be this. For any given type, you should decide whether your type cares about pinning or not. Most types do not care about pinning. They just go on using &self and &mut self as normal. Everything works as today (this is the “zero-conceptual-cost” goal). But some types do care about pinning. These are typically future implementations but they could be other special case things. In that case, you should explicitly implement !Unpin to declare yourself as pinnable. When you declare your methods, you have to make a choice Is the method read-only? Then use &self , that always works. Otherwise, use &mut self or pinned &mut self , depending… If the method is meant to be called before pinning, use &mut self . If the method is meant to be called after pinning, use pinned &mut self . This design works well so long as all mutating methods can be categorized into before-or-after pinning. If you have methods that need to be used in both settings, you have to start using workarounds – in the limit, you make two copies. How does MinPin compare to UnpinCell? Those of you who have been following the various posts in this area will recognize many elements from boats’ recent UnpinCell . While the proposals share many elements, there is also one big difference between them that makes a big difference in how they would feel when used. Which is overall better is not yet clear to me. Let’s start with what they have in common. Both propose syntax for pinned references/borrows (albeit slightly different syntax) and both include a type for “opting out” from pinning (the eponymous UnpinCell<T> in UnpinCell , Unpinnable<T> in MinPin). Both also have a similar “special case” around Drop in which writing a drop impl with fn drop(&mut self) disables safe pin-projection. Where they differ is how they manage generic structs like WrapFuture<F> , where it is not known whether or not they are Unpin . struct WrapFuture < F : Future > { future : F , } The r: pinned &mut WrapFuture<F> , the question is whether we can project the field future : impl < F : Future > WrapFuture < F > { fn method ( pinned & mut self ) { let f = pinned & mut r . future ; //      -------------------- //      Is this allowed? } } There is a specific danger case that both sets of rules are trying to avoid. Imagine that WrapFuture<F> implements Unpin but F does not – e.g., imagine that you have a impl<F: Future> Unpin for WrapFuture<F> . In that case, the referent of the pinned &mut WrapFuture<F> reference is not actually pinned, because the type is unpinnable. If we permitted the creation of a pinned &mut F , where F: !Unpin , we would be under the (mistaken) impression that F is pinned. Bad. UnpinCell handles this case by saying that projecting from a pinned &mut is only allowed so long as there is no explicit impl of Unpin for WrapFuture (“if [WrapFuture<F>] implements Unpin , it does so using the auto-trait mechanism, not a manually written impl”). Basically: if the user doesn’t say whether the type is Unpin or not, then you can do pin-projection. The idea is that if the self type is Unpin , that will only be because all fields are unpin (in which case it is fine to make pinned &mut references to them); if the self type is not Unpin , then the field future is pinned, so it is safe. In contrast, in MinPin, this case is only allowed if there is an explicit !Unpin impl for WrapFuture : impl < F : Future > ! Unpin for WrapFuture < F > { // This impl is required in MinPin, but not in UnpinCell } Explicit negative impls are not allowed on stable, but they were included in the original auto trait RFC. The idea is that a negative impl is an explicit, semver-binding commitment not to implement a trait. This is different from simply not including an impl at all, which allows for impls to be added later. Why would you prefer MinPin over UnpinCell or vice versa? I’m not totally sure which of these is better. I came to the !Unpin impl based on my axiom that pin is its own world – the idea was that it was better to push types to be explicitly unpin all the time than to have “dual-mode” types that masquerade as sometimes pinned and sometimes not. In general I feel like it’s better to justify language rules by the presence of a declaration than the absence of one. So I don’t like the idea of saying “the absence of an Unpin impl allows for pin-projection” – after all, adding impls is supposed to be semver-compliant. Of course, that’s much lesss true for auto traits, but it can still be true. In fact, Pin has had some unsoundness in the past based on unsafe reasoning that was justified by the lack of an impl. We assumed that &T could never implemented DerefMut , but it turned out to be possible to add weird impls of DerefMut in very specific cases. We fixed this by adding an explicit impl<T> !DerefMut for &T impl . On the other hand, I can imagine that many explicitly implemented futures might benefit from being able to be ambiguous about whether they are Unpin . What does your design axiom “ Pin is its own world” mean? The way I see it is that, in Rust today (and in MinPin, pinned places, UnpinCell, etc), if you have a T: !Unpin type (that is, a type that is pinnable), it lives a double life. Initially, it is unpinned, and you interact can move it, & -ref it, or &mut -ref it, just like any other Rust value. But once a !Unpin value becomes pinned to a place, it enters a different state, in which you can no longer move it or use &mut , you have to use pinned &mut : One-way transitions like this limit the amount of interop and composability you get in the language. For example, if my type has &mut methods, I can’t use them once the type is pinned, and I have to use some workaround, such as duplicating the method with pinned &mut . 3 In this specific case, however, I don’t think this transition is so painful, and that’s because of the specifics of the domain: futures go through a pretty hard state change where they start in “preparation mode” and then eventually start executing. The set of methods you need at these two phases are quite distinct. So this is what I meant by “pin is its own world”: pin is not very interopable with Rust, but this is not as bad as it sounds, because you don’t often need that kind of interoperability. How would Overwrite affect pin being in its own world? With Overwrite , when you pin a value in place, you just gain the ability to use pinned &mut , you don’t give up the ability to use &mut : flowchart TD
Unpinned[
    Unpinned: can access 'v' with '&' and '&mut'
]

Pinned[
    Pinned: can additionally access 'v' with 'pinned &mut'
]

Unpinned --
    pin 'v' in place (only if T is '!Unpin')
--> Pinned Making pinning into a “superset” of the capabilities of pinned means that pinned &mut can be coerced into an &mut (it could even be a “true subtype”, in Rust terms). This in turn means that a pinned &mut Self method can invoke &mut self methods, which helps to make pin feel like a smoothly integrated part of the language. 3 So does the axiom mean you think Overwrite is a bad idea? Not exactly, but I do think that if Overwrite is justified, it is not on the basis of Pin , it is on the basis of immutable fields . If you just look at Pin , then Overwrite does make Pin work better, but it does that by limiting the capabilities of &mut to those that are compatible with Pin . There is no free lunch! As Eric Holk memorably put it to me in privmsg: It seems like there’s a fixed amount of inherent complexity to pinning, but it’s up to us how we distribute it. Pin keeps it concentrated in a small area which makes it seem absolutely terrible, because you have to face the whole horror at once. 4 I think Pin as designed is a “zero-conceptual-cost” abstraction, meaning that if you are not trying to use it, you don’t really have to care about it. That’s worth maintaining, if we can. If we are going to limit what &mut can do, the reason to do it is primarily to get other benefits, not to benefit pin code specifically. To be clear, this is largely a function of where we are in Rust’s evolution. If we were still in the early days of Rust, I would say Overwrite is the correct call. It reminds me very much of the IMHTWAMA , the core “mutability xor sharing” rule at the heart of Rust’s borrow checker. When we decided to adopt the current borrow checker rules, the code was about 85-95% in conformance. That is, although there was plenty of aliased mutation, it was clear that “mutability xor sharing” was capturing a rule that we already mostly followed, but not completely. Because combining aliased state with memory safety is more complicated, that meant that a small minority of code was pushing complexity onto the entire language. Confining shared mutation to types like Cell and Mutex made most code simpler at the cost of more complexity around shared state in particular. There’s a similar dynamic around replace and swap. Replace and swap are only used in a few isolated places and in a few particular ways, but the all code has to be more conservative to account for that possibility. If we could go back, I think limiting Replace to some kind of Replaceable<T> type would be a good move, because it would mean that the more common case can enjoy the benefits: fewer borrow check errors and more precise programs due to immutable fields and the ability to pass an &mut SomeType and be sure that your callee is not swapping the value under your feet (useful for the “scope pattern” and also enables Pin<&mut> to be a subtype of &mut ). Why did you adopt pinned &mut and not &pin mut as the syntax? The main reason was that I wanted a syntax that scaled to Pin<Box<T>> . But also the pin! macro exists, making the pin keyword somewhat awkward (though not impossible). One thing I was wondering about is the phrase “pinned reference” or “pinned pointer”. On the one hand, it is really a reference to a pinned value (which suggests &pin mut ). On the other hand, I think this kind of ambiguity is pretty common. The main thing I have found is that my brain has trouble with Pin<P> because it wants to think of Pin as a “smart pointer” versus a modifier on another smart pointer. pinned Box<T> feels much better this way. Can you show me an example? What about the MaybeDone example? Yeah, totally. So boats [pinned places][] post introduced two futures, MaybeDone and Join . Here is how MaybeDone would look in MinPin, along with some inline comments: enum MaybeDone < F : Future > { Polling ( F ), Done ( Unpinnable < Option < F :: Output >> ), //   ---------- see below } impl < F : Future > ! Unpin for MaybeDone < F > { } //              ----------------------- // // `MaybeDone` is address-sensitive, so we // opt out from `Unpin` explicitly. I assumed // opting out from `Unpin` was the *default* in // my other posts. impl < F : Future > MaybeDone < F > { fn maybe_poll ( pinned & mut self , cx : & mut Context < '_ > ) { if let MaybeDone :: Polling ( fut ) = self { //                    --- // This is in fact pin-projection, although // it's happening implicitly as part of pattern // matching. `fut` here has type `pinned &mut F`. // We are permitted to do this pin-projection // to `F` because we know that `Self: !Unpin` // (because we declared that to be true). if let Poll :: Ready ( res ) = fut . poll ( cx ) { * self = MaybeDone :: Done ( Some ( res )); } } } fn is_done ( & self ) -> bool { matches! ( self , & MaybeDone :: Done ( _ )) } fn take_output ( pinned & mut self ) -> Option < F :: Output > { //         ---------------- //     This method is called after pinning, so it //     needs a `pinned &mut` reference... if let MaybeDone :: Done ( res ) = self { res . value . take () //  ------------ // //  ...but take is an `&mut self` method //  and `F:Output: Unpin` is known to be true. // //  Therefore we have made the type in `Done` //  be `Unpinnable`, so that we can do this //  swap. } else { None } } } Can you translate the Join example? Yep! Here is Join : struct Join < F1 : Future , F2 : Future > { fut1 : MaybeDone < F1 > , fut2 : MaybeDone < F2 > , } impl < F1 : Future , F2 : Future > ! Unpin for Join < F > { } //                           ------------------ // // Join is a custom future, so implement `!Unpin` // to gain access to pin-projection. impl < F1 : Future , F2 : Future > Future for Join < F1 , F2 > { type Output = ( F1 :: Output , F2 :: Output ); fn poll ( pinned & mut self , cx : & mut Context < '_ > ) -> Poll < Self :: Output > { // The calls to `maybe_poll` and `take_output` below // are doing pin-projection from `pinned &mut self` // to a `pinned &mut MaybeDone<F1>` (or `F2`) type. // This is allowed because we opted out from `Unpin` // above. self . fut1 . maybe_poll ( cx ); self . fut2 . maybe_poll ( cx ); if self . fut1 . is_done () && self . fut2 . is_done () { let res1 = self . fut1 . take_output (). unwrap (); let res2 = self . fut2 . take_output (). unwrap (); Poll :: Ready (( res1 , res2 )) } else { Poll :: Pending } } } What’s the story with Drop and why does it matter? Drop’s current signature takes &mut self . But recall that once a !Unpin type is pinned, it is only safe to use pinned &mut . This is a combustible combination. It means that, for example, I can write a Drop that uses mem::replace or swap to move values out from my fields, even though they have been pinned. For types that are always Unpin , this is no problem, because &mut self and pinned &mut self are equivalent. For types that are always !Unpin , I’m not too worried, because Drop as is is a poor fit for them, and pinned &mut self will be beter. The tricky bit is types that are conditionally Unpin . Consider something like this: struct LogWrapper < T > { value : T , } impl < T > Drop for LogWrapper < T > { fn drop ( & mut self ) { .. . } } At least today, whether or not LogWrapper is Unpin depends on whether T: Unpin , so we can’t know it for sure. The solution that boats and I both landed on effectively creates three categories of types: 5 those that implement Unpin , which are unpinnable ; those that do not implement Unpin but which have fn drop(&mut self) , which are unsafely pinnable ; those that do not implement Unpin and do not have fn drop(&mut self) , which are safely pinnable . The idea is that using fn drop(&mut self) puts you in this purgatory category of being “unsafely pinnable” (it might be more accurate to say being “maybe unsafely pinnable”, since often at compilation time with generics we won’t know if there is an Unpin impl or not). You don’t get access to safe pin projection or other goodies, but you can do projection with unsafe code (e.g., the way the pin-project-lite crate does it today). It feels weird to have Drop let you use &mut self when other traits don’t. Yes, it does, but in fact any method whose trait uses pinned &mut self can be implemented safely with &mut self so long as Self: Unpin . So we could just allow that in general. This would be cool because many hand-written futures are in fact Unpin , and so they could implement the poll method with &mut self . Wait, so if Unpin types can use &mut self , why do we need special rules for Drop ? Well, it’s true that an Unpin type can use &mut self in place of pinned &mut self , but in fact we don’t always know when types are Unpin . Moreover, per the zero-conceptual-cost axiom, we don’t want people to have to know anything about Pin to use Drop . The obvious approaches I could think of all either violated that axiom or just… well… seemed weird: Permit fn drop(&mut self) but only if Self: Unpin seems like it would work, since most types are Unpin . But in fact types, by default, are only Unpin if their fields are Unpin , and so generic types are not known to be Unpin . This means that if you write a Drop impl for a generic type and you use fn drop(&mut self) , you will get an error that can only be fixed by implementing Unpin unconditionally. Because “pin is its own world”, I believe adding the impl is fine, but it violates “zero-conceptual-cost” because it means that you are forced to understand what Unpin even means in the first place. To address that, I considered treating fn drop(&mut self) as implicitly declaring Self: Unpin . This doesn’t violate our axioms but just seems weird and kind of surprising. It’s also backwards incompatible with pin-project-lite. These considerations let me to conclude that actually the current design kind of puts in a place where we want three categories. I think in retrospect it’d be better if Unpin were implemented by default but not as an auto trait (i.e., all types were unconditionally Unpin unless they declare otherwise), but oh well. What is the forwards compatibility story for Overwrite ? I mentioned early on that MinPin could be seen as a first step that can later be extended with Overwrite if we choose. How would that work? Basically, if we did the s/Unpin/Overwrite/ change, then we would rename Unpin to Overwrite (literally rename, they would be the same trait); prevent overwriting the referent of an &mut T unless T: Overwrite (or replacing, swapping, etc). These changes mean that &mut T is pin-preserving. If T: !Overwrite , then T may be pinned, but then &mut T won’t allow it to be overwritten, replaced, or swapped, and so pinning guarantees are preserved (and then some, since technically overwrites are ok, just not replacing or swapping). As a result, we can simplify the MinPin rules for pin-projection to the following: Given a reference s: pinned &mut S , the rules for projection of the field f are as follows: &mut projection is allowed via &mut s.f . pinned &mut projection is allowed via pinned &mut s.f if S: !Unpin What would it feel like if we adopted Overwrite ? We actually got a bit of a preview when we talked about MaybeDone . Remember how we had to introduce Unpinnable around the final value so that we could swap it out? If we adopted Overwrite , I think the TL;DR of how code would be different is that most any code that today uses std::mem::replace or std::mem::swap would probably wind up using an explicit Unpinnable -like wrapper. I’ll cover this later. This goes a bit to show what I meant about there being a certain amount of inherent complexity that we can choose to distibute: in MinPin, this pattern of wrapping “swappable” data is isolated to pinned &mut self methods in !Unpin types. With Overwrite , it would be more widespread (but you would get more widespread benefits, as well). Conclusion My conclusion is that this is a fascinating space to think about! 6 So fun. Hat tip to Tyler Mandry and Eric Holk who discussed these ideas with me in detail. ↩︎ MinPin is the “minimal” proposal that I feel meets my desiderata; I think you could devise a maximally minimal proposal is even smaller if you truly wanted. ↩︎ It’s worth noting that coercions and subtyping though only go so far. For example, &mut can be coerced to & , but we often need methods that return “the same kind of reference they took in”, which can’t be managed with coercions. That’s why you see things like last and last_mut . ↩︎ ↩︎ I would say that the current complexity of pinning is, in no small part, due to accidental complexity , as demonstrated by the recent round of exploration, but Eric’s wider point stands. ↩︎ Here I am talking about the category of a particular monomorphized type in a particular version of the crate. At that point, every type either implements Unpin or it doesn’t. Note that at compilation time there is more grey area, as they can be types that may or may not be pinnable, etc. ↩︎ Also that I spent way too much time iterating on this post. JUST GONNA POST IT. ↩︎
