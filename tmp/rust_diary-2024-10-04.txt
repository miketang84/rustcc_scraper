https://rust-unofficial.github.io/too-many-lists/fifth.html
-->>-->>
Light (default) Rust Coal Navy Ayu Learning Rust With Entirely Too Many Linked Lists document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    }); An Ok Unsafe Singly-Linked Queue Ok that reference-counted interior mutability stuff got a little out of
control. Surely Rust doesn't really expect you to do that sort of thing
in general? Well, yes and no. Rc and Refcell can be great for handling
simple cases, but they can get unwieldy. Especially if you
want to hide that it's happening. There's gotta be a better way! In this chapter we're going to roll back to singly-linked lists and
implement a singly-linked queue to dip our toes into raw pointers and Unsafe Rust . NARRATOR: And I will point out the mistakes. And we won't make any mistakes. Let's add a new file called fifth.rs : // in lib.rs pub mod first; pub mod second; pub mod third; pub mod fourth; pub mod fifth; Our code is largely going to be derived from second.rs, since a queue is
mostly an augmentation of a stack in the world of linked lists. Still, we're
going to go from scratch because there's some fundamental issues we want to
address with layout and what-not.
======>
https://docs.rs/quick-builder/0.1.0/quick_builder/#alternatives
-->>-->>
Crate quick_builder Copy item path Settings Help Summary source Expand description § QuickBuilder: Compile-Time Builder with Enforcement of Run-Time Invariants This crate offers a simple, but powerful, compile-time builder pattern generator.
The philosophy is to verify as much as possible at compile-time, while also
providing a straightforward way to enforce run-time invariants. § When Should You Try QuickBuilder? Give QuickBuilder a shot if you want to derive a builder for your struct,
that makes it a compile error if you forget to set a field and allows you to specify run-time invariants for your struct that
are enforced at run-time and you can live with the more ascetic interface that the builder provides,
see the sections on limitations and alternatives. § Motivation There are great builder crates, like bon or typed-builder , that allow you
to create idiomatic builders enforcing that all necessary fields
have been set at compile-time. Like those crates, QuickBuilder
can generate a builder that only allows to call the final .build() method if
all fields were initialized. use quick_builder::QuickBuilder; #[derive(QuickBuilder)] struct ImageRef< 'a , T> {
    width: usize,
    height: usize,
    data: & 'a [T],
} fn main() { let image_data = & [ 1 , 2 , 3 , 4 , 5 , 6 ]; let imgref = ImageRef::builder()
        .width( 3 )
        .height( 2 )
        .data(image_data)
        .build();
} However, the example above is not the main usecase for QuickBuilder. If that’s
all you ever need to do, check out the bon or typed-builder crates. Those offer,
among other things, more exhaustive support for idioms like optional and
default parameters, as well as great ergonomics. QuickBuilder shines when
you additionally need to enforce run-time invariants about your data structure. § Enforcing Run-Time Invariants In the example above we might want to enforce a couple of invariants
about the data structure which we can only check at run-time. The following
example shows, how we can use QuickBuilder to enforce that… …the width of the image is greater 0 and the height of the image is an even number greater 0 and the product of width and height is equal to the length of the given slice. use quick_builder::QuickBuilder; #[derive(QuickBuilder)]
#[invariant(|my| my.width * my.height == my.data.len())] struct ImageRef< 'a , T> { #[invariant(|w| * w> 0 )] width: usize, #[invariant(check_height)] height: usize,
    data: & 'a [T],
} // if the conditions to check invariants are too
// unwieldy to put into a closure, you can also
// define a standalone function. fn check_height(height : & usize) -> bool { * height > 0 && * height % 2 == 0 } fn main() { let image_data = & [ 1 , 2 , 3 , 4 , 5 , 6 ]; let imgref = ImageRef::builder()
        .width( 3 )
        .height( 2 )
        .data(image_data)
        .build()
        .unwrap();
} One (or zero) #[invariant(...)] attributes can be applied to each field or
to the struct itself. The attributes take a closure or function name to check
if the invariant holds. The function (or closure) must take its
argument by reference and return a bool , where true means that the invariant
holds and false means it’s violated. As soon as an #[invariant(...)] attribute is encountered, the build function
changes its signature. It now returns an optional instance of the original
structure, where the optional contains a value if and only if all invariants
where upheld during construction. § Limitations Build Order : The builder function must be executed in the order of
field declarations in the struct. Typically, IDE support is good enough
to provide you with the next allowed option, so you don’t have to look
up the struct fields. The bon and typed-builder crates allow arbitrary
orders, but they don’t have a mechanism for enforcing run-time invariants. Default/Optional Arguments : there is no support for default or optional
arguments (yet). Weird Generics : The builder structure contains a bit of generic magic
and is not meant for passing around. Consuming Builder Pattern Only : The builder uses the consuming pattern always.
If you need to set fields conditionally, check out the apply_if crate. § Protecting Field Access: Getters If care about enforcing invariants about your data, you probably want to provide getters
to your fields rather than making them publicly accessible. In that case, you’ll
be happy to hear that this crate works seamlessly with the popular getset and derive-getters crates. Those offer derive macros for getters and setters. § Alternatives There is a great overview of builder crates by the bon team. Of those, to my knowledge, only the derive_builder crate provides a way to enforce run-time invariants. However, that crate
makes it a run-time error if not all required fields were set.
Some might argue that if we have run-time errors anyways (due to the invariants)
we might not care about that. But my philosophy is that I’d rather validate as
much as I can at compile-time and let run-time errors be run-time errors.
But that’s just me. Derive Macros § Quick Builder

======>
https://github.com/Cr0a3/ygen
-->>-->>
Repository files navigation README Code of conduct Apache-2.0 license Security Ygen - Yet another Code Generator Welcome to Ygen!
This repository contains the source code of the ygen project. Ygen is a toolkit for building fast and clean compilers using a memory safe api. Why ygen? You are probably wondering: why would I choose ygen and not llvm or cranelift??
Here are a few reasons: Simplicity : One of ygens main focus is simplicity which means to us that as much code as possible is readable and shared Similare API : Ygens API is very similar to LLVMs API for example i designed the IRBuilder to be very similar to the Builder from LLVM Traits : Ygen uses a lot of traits to overload functions. Great examples are the Build... functions from the IRBuilder to build ir nodes Warning This project is still early in its developement. Bugs and miscompilations are expected. ONLY USE YGEN FOR TOY COMPILERS Contributions Simple example Here is a simple example on how to use Ygen to build an add function: use std :: error :: Error ; use Ygen :: prelude :: * ; pub fn main ( ) -> Result < ( ) , Box < dyn Error > > { let mut module = Module ( ) ; let mut builder = IRBuilder ( ) ; let ty = FnTy ( vec ! [ TypeMetadata :: i32 , TypeMetadata :: i32 ] , TypeMetadata :: i32 ) ; let func = module . add ( "add" , & ty ) ; func . extrn ( ) ; // make function externally visible let entry = func . addBlock ( "entry" ) ; builder . positionAtEnd ( entry ) ; let val = builder . BuildAdd ( ty . arg ( 0 ) , ty . arg ( 1 ) ) ; builder . BuildRet ( val ) ; module . verify ( ) . print ( ) ; eprintln ! ( "{}" ,
        module.dumpColored ( ) ) ; Ok ( ( ) ) } When executed this simple program builds an add function and dumps it's ir: define i32 @add ( i32 %0 , i32 %1 ) {
 entry: %2 = add i32 %0 , %1 ret i32 %2 } You can add following lines (you need to include std::fs::Path ) to compile the IR down to assembly: module . emitToAsmFile ( Triple :: host ( ) , & mut initializeAllTargets ( Triple :: host ( ) ) ? , Path :: new ( "out.asm" ) ) ? ; Support Ygen currently supports following architectures Name Full ir Full isa x64 Yes No Copyright This project is owned by Cr0a3 and licensed under the Apache2 License
======>
https://www.reddit.com/r/rust/comments/1fvfgx0/ygen_release_012/
-->>-->>
Go to rust r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online • 1 day ago Cr0a3 ADMIN MOD Ygen: release 0.1.2 Hi, I recently released the version 0.1.2 of ygen. Ygen is my small (16k locs) code generation libary. It's not designed to be used by other people because it is just a little code generation learning project. What features does ygen currently has? Ygen currently supports these IR nodes: alloca is used to allocate a variable on the stack. ( Code example from the tests ) assign an variable assignment ( Code example from the tests ) br either an unconditional branch or an conditional branch ( Code example from the tests ) call a simple call ( Code example from the tests ) cast a cast between two types cmp compares two variables ( Code example from the tests ) load loads an value from an memory pointer add performs the add operation on two variables sub performs the sub operation on two variables xor performs the xor operation on two variables or performs the or operation on two variables and performs the and operation on two variables mul performs the mul operation on two variables div performs the div operation on two variables ret returns an variable or value store stores an variable/value into an pointer Optimizations: constant evaluation: ygen can pre compute constant values and inline const variables dead node elimination: ygen can remove unused variables Debug metadata: you can add debug metadata Architecturs: Ygen currently only supports x86_64 Targets: I only tested Windows and Linux but theoretically all x86_64 targets wich either have WindowsFastcall or SystemV as their calling convention should work I am only 13yrs old so do not expect to much . Ygen also doesn't stick to the naming convention (please don't judge my by that) Here's the github: https://github.com/Cr0a3/ygen And it's website (made in 1 day): https://ygen.vercel.app/ Bye Read more Grammarly • Official • Promoted Believe in your ideas, but struggle to convey them effectively? Grammarly’s AI writing assistant ensures your intelligence shines through in every paper. Add a Comment Sort by: Best Open comment sort options Best Top New Controversial Old Q&A Ok-Ingenuity-6262 • 1d ago • THIRTEEN??? Bro no hate but I hope you get enough social life. And very impressive project. Reply reply Cr0a3 • 1d ago • Thank you very much! I play with my friends every day video games after school and only work on ygen like 2 or 3 hours Reply reply 5 more replies 5 more replies More replies More replies BionicVnB • 1d ago • Bro is 13 and more talented than I could ever be Reply reply Cr0a3 • 23h ago • Thank you Reply reply More replies Comun4 • 1d ago • Wow, that's very cool project Unfortunately, reddit is 14+ so we kinda need to ban you 😅 /jk Reply reply Cr0a3 • 23h ago • Bro Reply reply LeSaR_ • 21h ago • me when i spread misinformation on the internet Reply reply More replies Top 1% Rank by size Public Anyone can view, post, and comment to this community More posts you may like Related Rust Programming open-source software Technology Free software Software Information & communications technology forward back r/europe r/europe Europe: 50 (+6) countries, 230 languages, 746M people… 1 subreddit. 7.5M Members 1.4K Online On this day in 1919 Greek troops invaded Izmir, Turkey 258 upvotes · 362 comments r/exmormon r/exmormon A forum for ex-mormons and others who have been affected by Mormonism to get support and share news, commentary, and comedy about the Mormon church. 312K Members 240 Online Getting this email warmed my cold, non-believing heart 845 upvotes · 254 comments r/pics r/pics A place for photographs, pictures, and other images. 31M Members 3.7K Online Left is a photo, right is a drawing. 219 upvotes · 20 comments Promoted r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online Practice - v0.1.0 Release 🚀 123 upvotes · 8 comments r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online ureq 3.x release candidate 1 104 upvotes · 11 comments r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online Loco.rs v0.9.0 Released: new docs, new website, new features! 205 upvotes · 60 comments r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online Reading Large (100GB+) Files. 146 upvotes · 52 comments r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online Rust for Android 414 upvotes · 38 comments Promoted r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online Binsider - A TUI for analyzing Linux binaries like a boss! 355 upvotes · 26 comments r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online Pax enters Beta: Rust GUIs with an integrated design tool 242 upvotes · 54 comments r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online Support for SQLite's JSON/JSONB has landed on diesel 122 upvotes · 7 comments r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online Rust to .NET compiler - end of GSoC, what now? 182 upvotes · 19 comments r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online Could rust theoretically achieve better optimisation with a costum backend, that takes more advantage of the rich type system Information that LLVM? 102 upvotes · 39 comments r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online What's the difference between `FnOnce`, `Fn` and `FnMut` 100 upvotes · 48 comments r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online A better way to manage environment variables 🛠️! 130 upvotes · 20 comments r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online Help wanted for a crate :) 142 upvotes · 16 comments r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online Use Type-State pattern without the ugly code 206 upvotes · 51 comments r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online Come test a novel "trait debugger" for Rust 108 upvotes · 5 comments r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online Quality of RustRover versus rust-analyzer 110 upvotes · 139 comments r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online So what do you use for Rust development? 145 upvotes · 213 comments r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online Giving Bevy the Quick-Start Guide it deserves 133 upvotes · 7 comments r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online The One Billion Rows Challenge - My solution in Rust - 1 second 126 upvotes · 40 comments r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online Hyperion - 10k player Minecraft Game Engine 706 upvotes · 52 comments r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online PSA: Use #[diagnostic::on_unimplemented]! It's amazing! 300 upvotes · 17 comments r/rust r/rust A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity. 313K Members 158 Online We have coded a multiplayer Minecaft clone with glium (OpenGL) to learn Rust 128 upvotes · 19 comments

======>
https://github.com/LGUG2Z/komorebi/releases/tag/v0.1.29
-->>-->>
Releases v0.1.29 v0.1.29 Latest Latest Compare Choose a tag to compare Could not load tags Nothing to show {{ refName }} default Loading View all tags github-actions released this 28 Sep 01:54 · 11 commits to master
          since this release v0.1.29 818ac34 v0.1.29 (2024-09-27) - Beirut Bug Fixes wm : add layout edge index awareness ( 21bd09e4 ) wm : cross-border focus direction awareness ( c3f13570 ) bar : use truncated labels for titles ( 3720ce42 ) wm : cross-border move direction awareness ( 1080159e ) bar : read mouse follows focus from state ( 6addfed1 ) bar : use custom windows-icons w/o panics ( 254fcc98 ) wm : hot reload cross boundary behaviour changes ( 7005a01d ) bar : fmt battery percentage without decimals ( 286bb007 ) wm : grow monitors vec to accomodate idx prefs ( c06d9afa ) animation : enable cross-monitor animations ( 3c035287 ) wm : socket cleanup on exit ( 821a1247 ) wm : exclude minimized hwnds from show event ( 13e2cbc7 ) wm : mouse resize on right and bottom edges ( ff653e78 ) cli : correct cycle-layout prev/next seq ( 6d038b8b ) borders : maximize compat w/ komorebi impl ( b5eafc6b ) wm : apply window based offsets to monocles ( c3679673 ) transparency : handle multi-monitor monocles ( 780635c8 ) animation : disable on cross-monitor drag ( 6ea71834 ) Code Refactoring deps : unify versions across workspace pkgs ( 360d0915 ) bar : change panics to error logs ( df409902 ) wm : reduce process_event log noise ( 8f7b9202 ) client : use public interface exclusively ( 81451cb1 ) Features bar : add quickstart flag, remove yaml format ( 109227b7 ) bar : expand komorebi layout subwidget ( 01ccf70a ) bar : expand focused window subwidget ( 182c1e6a ) bar : add font size config opt ( 14d2ebd7 ) cli : generate json schemas locally ( df19d063 ) cli : update enable-autostart cmd for bar ( 96d094d9 ) wm : add replace configuration socket message ( 2916256e ) bar : hotloading for viewport inner_size ( de3d4d0d ) themes : update bar on komorebi.json reload ( b69db863 ) themes : add + integrate komorebi-themes lib ( 45894be4 ) bar : add komorebi-bar ( bc67936d ) wm : add cross boundary behaviour options ( b799fd30 ) cli : add focus-stack-window cmd ( f722905b ) cli : add toggle-transparency cmd ( 0f9c23b6 ) Documentation mkdocs : generate latest cli docs ( d6ae81af ) privacy : add privacy policy ( d110e12a ) mkdocs : add komorebi-bar to getting started ( 21a21383 ) license : fork polyform strict to explicitly allow changes ( 6ba0ba79 ) Chore release : v0.1.29 ( 818ac340 ) deps : bump windows-rs from 0.57 to 0.58 ( ddb600f7 ) deps : bump windows-rs from 0.54 to 0.57 ( 167ec928 ) deps : cargo update ( 50b89cc1 ) deps : bump regex from 1.10.5 to 1.10.6 ( 45a59418 ) deps : bump clap from 4.5.9 to 4.5.13 ( f54097f0 ) deps : bump dunce from 1.0.4 to 1.0.5 ( 29b14f8d ) deps : bump which from 6.0.1 to 6.0.2 ( a1cf5ba2 ) deps : bump serde_json from 1.0.120 to 1.0.122 ( a60e5a77 ) deps : bump openssl from 0.10.64 to 0.10.66 ( d5bec7af ) deps : bump thiserror from 1.0.62 to 1.0.63 ( 974aa0d0 ) dev : begin v0.1.29-dev ( 7653495e ) Assets 5 Loading 6 mort65, Aaqil101, Mickychen00, azinsharaf, 0xjairo, and justraven reacted with thumbs up emoji 10 ClixTW, JiangpengLI86, Lucho32-byte, codyduong, obolenski, CtByte, Mickychen00, 0xjairo, justraven, and thearturca reacted with hooray emoji 1 xidsyed reacted with heart emoji All reactions 6 reactions 10 reactions 1 reaction 14 people reacted

======>
https://github.com/shelbyJenkins/llm_client
-->>-->>
Repository files navigation README MIT license The Easiest Rust Interface for Local LLMs # For Mac (CPU and GPU), windows (CPU and CUDA), or linux (CPU and CUDA) llm_client = " * " This will download and build llama.cpp . See build.md for other features and backends like mistral.rs. use Llmclient :: prelude :: * ; // Loads the largest quant available based on your VRAM or system memory let llm_client = LlmClient :: llama_cpp ( ) . mistral7b_instruct_v0_3 ( ) // Uses a preset model . init ( ) // Downloads model from hugging face and starts the inference interface . await ? ; Several of the most common models are available as presets. Loading from local models is also fully supported. See models.md for more information. Features Automated build and support for CPU, CUDA, MacOS Easy model presets and quant selection Novel cascading prompt workflow for CoT and NLP workflows. DIY workflow creation supported! Breadth of configuration options (sampler params, retry logic, prompt caching, logit bias, grammars, etc) API support for OpenAI, Anthropic, Perplexity, and any OpenAI compatible API An Interface for Deterministic Signals from Probabilistic LLM Vibes In addition to basic LLM inference, llm_client is primarily designed for controlled generation using step based cascade workflows. This prompting system runs pre-defined workflows that control and constrain both the overall structure of generation and individual tokens during inference. This allows the implementation of specialized workflows for specific tasks, shaping LLM outputs towards intended, reproducible outcomes. let response : u32 = llm_client . reason ( ) . integer ( ) . instructions ( ) . set_content ( "Sally (a girl) has 3 brothers. Each brother has 2 sisters. How many sisters does Sally have?" ) . return_primitive ( ) . await ? ; // Recieve 'primitive' outputs assert_eq ! ( response, 1 ) This runs the reason one round cascading prompt workflow with an integer output. This method significantly improves the reliability of LLM use cases. For example, there are test cases this repo that can be used to benchmark an LLM. There is a large increase in accuracy when comparing basic inference with a constrained outcome and a CoT style cascading prompt workflow . The decision workflow that runs N count of CoT workflows across a tempature gradient approaches 100% accuracy for the test cases. I have a full breakdown of this in my blog post, " Step-Based Cascading Prompts: Deterministic Signals from the LLM Vibe Space ." Jump to the readme.md of the llm_client crate to find out how to use them. Examples device config - customizing your inference config basic completion - the most basic request available basic primitive - returns the request primitive reason - a cascade workflow that performs CoT reasoning before returning a primitive decision - uses the reason workflow N times across a temperature gradient extract urls - a cascade workflow that extracts all URLs from text that meet a predict Docs llm_client readme.md docs directory Guides Limiting power in Nvidia GPUs Blog Posts Step-Based Cascading Prompts: Deterministic Signals from the LLM Vibe Space Roadmap Improve the Cascading workflow API to be easier. Refactor the benchmarks module for easy model comparison. WebUI client for local consumption. Server mode for "LLM-in-a-box" deployments Full Rust inference via mistral.rs or candle . Dependencies llm_utils is a sibling crate that was split from the llm_client. If you just need prompting, tokenization, model loading, etc, I suggest using the llm_utils crate on it's own. llm_interface is a sub-crate of llm_client. It is the backend for LLM inference. llm_devices is a sub-crate of llm_client. It contains device and build managment behavior. llama.cpp is used in server mode for LLM inference as the current default. mistral.rs is available for basic use, but is a WIP. Contact Shelby Jenkins - Here or Linkedin

======>
https://github.com/alexpasmantier/grip-grab
-->>-->>
Repository files navigation README Unlicense license grip-grab ( gg ) 🧤 A fast, more lightweight ripgrep alternative for daily use cases. ❯ gg " \b(Read|Write)Half[^<] " tokio/src grip-grab.mp4 Installation Using Cargo cargo install grip-grab NOTE: if using zsh with the git plugin, you might need to unalias gg in order for grip-grab's gg to work: echo ' unalias gg ' >> ~ /.zshrc source ~ /.zshrc Benchmarks The general idea With default settings for both tools, gg will typically be faster than rg on small to moderatly sized codebases (<= a couple milion lines) running on everyday machines because of its default thread heuristic. rg will typically be faster out of the box on larger corpora (think a checkout of the linux kernel) and machines with more logical cpus. Note that you still can tweak gg with the -T argument to achieve similar performance in those cases. The following discussion with ripgrep's author on HackerNews might also provide more insights regarding this tool's performance (including more benchmarks across different machines and corpora). NOTE : The following benchmarks were run on an M3 Macbook Pro with 16GB of RAM and 8 logical CPUs. The curl codebase (approx. half a milion lines) https://github.com/curl/curl hyperfine -m 200 " gg '[A-Z]+_NOBODY' . " " rg '[A-Z]+_NOBODY' . " " ggrep -rE '[A-Z]+_NOBODY' . " Benchmark 1: gg '[A-Z]+_NOBODY' .
  Time (mean ± σ):      18.5 ms ±   0.7 ms    [User: 10.5 ms, System: 47.9 ms]
  Range (min … max):    17.0 ms …  19.9 ms    200 runs

Benchmark 2: rg '[A-Z]+_NOBODY' .
  Time (mean ± σ):      37.0 ms ±   4.6 ms    [User: 15.1 ms, System: 201.0 ms]
  Range (min … max):    23.3 ms …  60.5 ms    200 runs

Benchmark 3: ggrep -rE '[A-Z]+_NOBODY' .
  Time (mean ± σ):      68.5 ms ±   0.6 ms    [User: 27.2 ms, System: 40.4 ms]
  Range (min … max):    64.6 ms …  70.4 ms    200 runs

Summary
  gg '[A-Z]+_NOBODY' . ran
    2.00 ± 0.26 times faster than rg '[A-Z]+_NOBODY' .
    3.71 ± 0.14 times faster than ggrep -rE '[A-Z]+_NOBODY' . Plaintext searches hyperfine -m 100 " gg 'test' " " rg 'test' " " ggrep -rE 'test' " Benchmark 1: gg 'test'
  Time (mean ± σ):      22.3 ms ±   1.1 ms    [User: 16.5 ms, System: 51.0 ms]
  Range (min … max):    20.4 ms …  27.7 ms    100 runs

Benchmark 2: rg 'test'
  Time (mean ± σ):      49.7 ms ±   2.7 ms    [User: 23.4 ms, System: 298.3 ms]
  Range (min … max):    42.0 ms …  55.5 ms    100 runs

Benchmark 3: ggrep -rE 'test'
  Time (mean ± σ):      52.3 ms ±   0.9 ms    [User: 14.6 ms, System: 37.0 ms]
  Range (min … max):    50.1 ms …  56.9 ms    100 runs

Summary
  gg 'test' ran
    2.23 ± 0.16 times faster than rg 'test'
    2.34 ± 0.12 times faster than ggrep -rE 'test' The tokio codebase (approx. 160k lines) https://github.com/tokio-rs/tokio hyperfine -m 200 " gg 'in<\w, W>' " " rg 'in<\w, W>' " " ggrep -r 'in<[[:alnum:]], W>' " Benchmark 1: gg 'in<\w, W>'
  Time (mean ± σ):       7.4 ms ±   0.7 ms    [User: 4.5 ms, System: 6.8 ms]
  Range (min … max):     6.0 ms …  10.3 ms    208 runs

Benchmark 2: rg 'in<\w, W>'
  Time (mean ± σ):       8.8 ms ±   0.8 ms    [User: 5.9 ms, System: 16.5 ms]
  Range (min … max):     6.7 ms …  10.7 ms    200 runs

Benchmark 3: ggrep -r 'in<[[:alnum:]], W>'
  Time (mean ± σ):     118.3 ms ±   2.1 ms    [User: 100.8 ms, System: 16.5 ms]
  Range (min … max):   114.3 ms … 127.4 ms    200 runs

Summary
  gg 'in<\w, W>' ran
    1.19 ± 0.15 times faster than rg 'in<\w, W>'
   15.92 ± 1.54 times faster than ggrep -r 'in<[[:alnum:]], W>' Plaintext searches These typically take <5ms on the tokio repository which is too low to benchmark with a tool like hyperfine. The neovim codebase (approx. 1.3 milion lines) https://github.com/neovim/neovim hyperfine --warmup 100 " gg '[a-z]+_buf\b' " " rg '[a-z]+_buf\b' " " ggrep -rE '[a-z]+_buf\b' " Benchmark 1: gg '[a-z]+_buf\b'
  Time (mean ± σ):      19.0 ms ±   1.2 ms    [User: 12.4 ms, System: 54.4 ms]
  Range (min … max):    16.8 ms …  22.6 ms    113 runs

Benchmark 2: rg '[a-z]+_buf\b'
  Time (mean ± σ):      36.0 ms ±   4.9 ms    [User: 14.8 ms, System: 200.5 ms]
  Range (min … max):    23.9 ms …  46.2 ms    75 runs

Benchmark 3: ggrep -rE '[a-z]+_buf\b'
  Time (mean ± σ):      75.7 ms ±   0.9 ms    [User: 36.3 ms, System: 39.4 ms]
  Range (min … max):    74.1 ms …  78.1 ms    36 runs

Summary
  gg '[a-z]+_buf\b' ran
    1.89 ± 0.29 times faster than rg '[a-z]+_buf\b'
    3.99 ± 0.26 times faster than ggrep -rE '[a-z]+_buf\b' Plaintext searches hyperfine --warmup 100 -m 100 " gg 'test' " " rg 'test' " " ggrep -rE 'test' " Benchmark 1: gg 'test'
  Time (mean ± σ):      21.0 ms ±   0.8 ms    [User: 15.3 ms, System: 48.1 ms]
  Range (min … max):    18.9 ms …  23.2 ms    114 runs

Benchmark 2: rg 'test'
  Time (mean ± σ):      42.4 ms ±   3.6 ms    [User: 19.5 ms, System: 253.3 ms]
  Range (min … max):    34.9 ms …  63.4 ms    100 runs

Benchmark 3: ggrep -rE 'test'
  Time (mean ± σ):      65.3 ms ±   1.6 ms    [User: 27.8 ms, System: 36.7 ms]
  Range (min … max):    63.2 ms …  78.4 ms    100 runs

Summary
  gg 'test' ran
    2.02 ± 0.19 times faster than rg 'test'
    3.11 ± 0.15 times faster than ggrep -rE 'test' Usage ❯ gg --help A faster, more lightweight ripgrep alternative for day to day usecases.

Usage: gg [OPTIONS] [PATTERN] [PATHS]... [COMMAND]

Commands:
  upgrade  Upgrade the crate to its latest version
  help     Print this message or the help of the given subcommand(s)

Arguments:
  [PATTERN]   a regex pattern to search for
  [PATHS]...  path in which to search recursively

Options:
  -e, --patterns <PATTERNS>
          you can specify multiple patterns using -e "pattern1" -e "pattern2" etc
  -I, --ignore-paths <IGNORE_PATHS>
          paths to ignore when recursively walking target directory
  -G, --disregard-gitignore
          disregard .gitignore rules when recursively walking directory (defaults to false)
  -T, --n-threads <N_THREADS>
          number of threads to use [default: 4]
  -U, --multiline
          enable multiline matching
      --json
          output in JSON format
  -f, --file-paths-only
          output file paths only
  -A, --absolute-paths
          output absolute paths (defaults to relative)
  -C, --disable-colored-output
          disable colored output (colored by default)
  -t, --filter-filetypes <FILTER_FILETYPES>
          filter on filetype (defaults to all filetypes)
  -H, --disable-hyperlinks
          disable hyperlinks in output (defaults to false)
  -D, --disable-devicons
          disable devicons in output (defaults to false)
  -h, --help
          Print help
  -V, --version
          Print version Upgrading gg You may upgrade gg to its latest version by running: gg upgrade Upgrade the crate to its latest version

Usage: gg upgrade [OPTIONS]

Options:
  -f, --force  Optional flag for force upgrade
  -h, --help   Print help gg_upgrade.mp4 Examples Basic usage ❯ gg " \b(Read|Write)Half[^<] " tokio/src JSON output ❯ gg --json unsplit tokio/src | jq Filenames only ❯ gg -f " \b(Read|Write)Half[^<] " tokio/src Notes This lightweight utility is largely based on a couple of crates from the extraordinary ripgrep tool.
Its aim is to provide a minimal and lightweight version that can be easily integrated in other programs for search-related purproses.

======>
https://old.reddit.com/r/rust/comments/1fvr8u1/why_this_code_snippet_violates_miri/
-->>-->>
I am writing a    An Ok Unsafe Queue    following    Too Many List   . I learn the stacked borrows but still not quite understand why these code snippet violates miri.   

   pub fn push(&mut self, elem: T) {
    let mut new_tail = Box::new(Node { elem, next: None });

    let raw_tail: *mut _ = &mut *new_tail;

    if !self.tail.is_null() {
        // Non-empty queue
        // This line violates stacked borrow, and can't satisfy miri's check.
        // But WHY?
        unsafe {
            (*self.tail).next = Some(new_tail);
        }
    } else {
        // Empty queue
        self.head = Some(new_tail);
    }

    self.tail = raw_tail;
}
   

   I know under miri's rule, I should not modify    new_tail   's value by variable other than    raw_tail   . But is these modification on    new_tail    in unsafe code? Why the line    self.head = Some(new_tail)    doesn't violate miri?   

   Here    is the code.   
   

======>
https://flawless.dev/docs/
-->>-->>
Introduction to durable execution Flawless is a durable execution engine for Rust. But what is durable execution actually? The easiest way to think about durable execution is as code that runs until completion ,
even in the presence of external failure . The external failure part is very
important. Rust as a language already pushes developers to explicitly handle errors. Almost every
API touching the operating system can fail and returns a Result , letting the
developer decide what should happen in that case. This is great! But there are some
failure scenarios that we can't handle directly from code. For example, if the
process executing the code is shut down. Can't if-else a kill -9 . That's what I like to
call an external failure . Flawless gives us tools to deal with such failures directly
from code. Let's look at some code and see how external failures can affect your system! // extend_subscription.rs fn extend_subscription ( user : User) { // 1. Charge user's credit card. let transaction = stripe_api::charge_card(user. card ()); // 2. Send invoice to user. let invoice = generate_invoice (user, transaction); loops_api::send_invoice(user. email (), invoice); // 3. Extend subscription. subscription_service::extend(user. id (), Month::new( 1 )); } This is a fairly straight forward function. It charges the credit card of a user, sends
an invoice to the same user and extends their subscription. And in the majority of cases
it will work just fine. However, there are a few cases where it might fail, or even worse, leave the system in an inconsistent state. One such case would be if the VM is restarted by an administrator to apply a security
update. Right at the moment when this function is executing! Maybe the credit card was
charged, but the code to extend the subscription was never called. Resulting in a very
upset customer. The most obvious way to protect against such scenarios is to create some kind of state
machine and persist it to a database/queue. So next time the app is started up again, it
knows exactly how far it got and can continue. Of course, this is not enough. Failures can come at the most inconvenient of times. What
happens if we persisted that an HTTP call to the Stripe API is about to be called, but
don't know if it finished. Is it safe to continue executing and repeating the call? Is
the user going to be charged twice? Idempotence and retry safety are other
topics that we need to care about. At this point we are developing a very sophisticated
state machine, with complex resume rules. Flawless takes this burden away from us. It allows us to just
write business logic instead, and gives us tools to deal with such failures directly from
the code. Similar to how a database abstracts away all the little quirks of the file-system API and
gives the developer a robust way to store their data, durable execution does the same for
running code. It allows you to resume the execution from any arbitrary point and gives you
tools to correctly model retries. How does it work? The most naive way of implementing a durable execution system would be to snapshot the
whole thing. Stack, heap and registers. After every instruction! This would also be a very inefficient and resource intensive task. Flawless takes a much
leaner approach. It uses the fact that modern CPUs are very fast , and usually a much
cheaper resource than memory, storage or networking. In the case of failure, it will
re-execute the code from the beginning, but only the deterministic parts of it. Everything that has a side effect, like HTTP calls, is executed only once and the result
of the operation persisted to a log file. The log turns side effects into deterministic
executions, if we ever need to re-execute the function. The following animation demonstrates this visually. workflow.rs × restarting ... side effect log > 63 64 let user = "Adele Goldberg" ; deterministic 65 let comic_id : u32 = flawless::rand::random() ; side effect 66 let url = format!( "https://xkcd.com/{comic_id}/" ) ; deterministic 67 let content = flawless_http::get( url ).send() ; side effect 68 let quote = parse_comic( content ) ; deterministic 69 let greeting = format!( "Hi {user}! //
            '{quote}'" ) deterministic 70 Error: Execution Interrupted! Machine unexpectedly rebooted. Execution Completed! ... recv msg {...} HTTP request send msg {...} get clock time _ _ _ > ▓———————————————————————————————————————————————————————————————————————————█ Only the minimal amount of data is preserved to disk and everything else is recalculated
on demand. Flawless also uses WebAssembly as the compilation target, to guarantee
determinism across operating systems and CPU architectures. You can start a workflow on
one machine and finish it on another. But from the perspective of an outside observer, it
seems as if the code just executes from start to finish. Only the side effects, that are
guaranteed to execute once, can be observed from the outside. Flawless uses this log mechanism to hook back into the code. This allows us to
programmatically handle external failures. Let's look at the following example. let result = flawless_http::post( "https://takes-a-long-time.com" ) . body (form) . send (); If we have a service that takes a very long time to respond to our HTTP request, it could
happen that an external failure happens while we are still waiting for the response.
Flawless uses a double commit system to detect if we actually got a response when
re-running some side effect. If this is not the case, the call will return an error of
kind ErrorKind::RequestInterrupted . With this, we are bringing
external failures back into our code. If we know that it's safe to retry the request, we can just signalize this directly from
the code. let result = flawless_http::post( "https://takes-a-long-time.com" ) . body (form) . idempotent () . send (); Now, Flawless will always retry the code, even if it failed mid-request. Use cases Once you have this guarantee, that a piece of code will run until the end, even if
temporarily interrupted, the abstractions you can build on top of it are much more
interesting. Let's look at two of them, long-running workflows and transactional behavior. Long-running workflows The longer something is executing, the more likely it is that it will fail in the middle
of the execution, and the harder it becomes to manually construct a state machine to
resume from an arbitrary point. That's where durable execution shines. Functions that need to run for months, years or even forever, are a valid pattern when it
comes to durable execution. Throwing in a casual sleep(1 year) into your business logic
is not a big deal, because we can completely shut off this one "thread" for a year. We
already have the means to resume it from any point. During this period it will
use 0 CPU and 0 memory resources. Transactional behavior You have probably heard of database transactions. They ensure that all database operations
inside a transaction are successfully performed, or none get executed. Leaving the system
in a consistent state. But what do you do when your operations are spread across different
microservices, external APIs or different databases? You can't have a transaction start in
PostgreSQL and finish in MySQL. Durable execution lets you build such a system using the Saga pattern . If you can
guarantee that all steps of a transaction or the reverting logic (in case of failure)
are going to be executed, it becomes "trivial" to build very robust transactional systems. There are many other patterns that can be built on top of durable execution. In the end,
durable execution is just code, so almost anything can be expressed with it. Wondering if it would be a good solution for your use case? Join the Flawless discord and tell us more about it! Ready to try it out? Flawless is a single binary that you run as a server and send your workflows to. If you
would like to try Flawless, check out the installation instructions .
======>
https://old.reddit.com/r/rust/comments/1fwc3n0/im_having_trouble_getting_into_it/
-->>-->>
Hi so I’ve been trying to learn rust for the past 3 months or so coming from high-level languages like Typescript, Python etc…   

   I’m still pretty young so I have a lot of time, but it’s kinda de-motivating me to learn because there are a lot of concepts, like memory management, pointers, and other terms I don’t remember that are very abstract to me.   

   What should I do? I’m really interested in learning but there’s some obstacles in the way…   
   

======>
https://old.reddit.com/r/rust/comments/1fw5ij0/quickbuilder_010_a_compiletime_verified_builder/
-->>-->>
Announcing    quick-builder   : a compile-time verified builder that also allows enforcing run-time invariants.    

   Try it on crates:    https://crates.io/crates/quick-builder   

   Short Overview   

   If you want to derive a builder pattern that both forces you to initialize all fields at compile time and also allows you to enforce run-time invariants, you might be interested in my    quick-builder    crate. Here's an example that's hopefully rather self explanatory:   

   ```rust   

   derive(QuickBuilder)]   

   [invariant(|my| my.width * my.height == my.data.len())]   

   struct ImageRef<'a, T> {
    #[invariant(|w|*w>0)]
    width: usize,
    #[invariant(check_height)]
    height: usize,
    data: &'a [T],
}   

   // if the conditions to check invariants are too
// unwieldy to put into a closure, you can also
// define a standalone function.
fn check_height(height :&usize) -> bool {
  *height > 0 && *height % 2 == 0
}   

   fn main() {
    let image_data = &[1, 2, 3, 4, 5, 6];
    let imgref = ImageRef::builder()
        .width(3)
        .height(2)
        .data(image_data)
        .build();
}
```   

   Limitations and Alternatives   

   I've written a    section in the docs    about alternatives. In short: my crate fills a niche between existing compile-time verified builders (which are great) and purely run-time verified builders (which are also great). It is (as of yet) not as nearly as flexible as those, but it serves people who want things that are detectable at compile time to be detected at compile time and also allow enforcing run-time invariants. It's well tested and documented, so I'm happy for people to give it a go and let me know.   

   Feedback Request   

   If you can see yourself using this crate, I'm happy to gather your feedback because I'd like to get some ideas for how to evolve how the builder communicates broken invariants. Right now it returns an    Option<T>   , but there are many other ways of skinning this cat and I'd like to hear what people think.   
   

======>
https://old.reddit.com/r/rust/comments/1fw463d/ygen_now_supports_phi/
-->>-->>
Hi,   

   In my    last post    (yesterday) i released ygen 0.1.2.   

   Today i added the    phi    ir node which is a big milestone in the development of ygen.   

   Why is the phi node so important?   

   The `phi` node is used very much.   

   Let's say for example this rust code:   

   fn example(a: i32) -> i32 {
   let b = if a == 0 {
        5 
   } else { a };

   return b;
}
   

   When optimizations are turned on it would compile to this (i think):   

   define i32 (i32 %a) {
  %1 = icmp eq i32 %a, 0
  br i1 %1, label %cond.yes, label %cond.no

cond.yes:
  %5 = add i32 5, 0
  br label %cond.resume

cond.no: 
  br label %cond.resume

cond.resume:
  %out = phi i32 [%5, %cond.yes], [%a, %cond.no]
  ret i32 %out
}
   

   NOTE: it wouldn't output above code (it would use the       select       instruction)   

   Instead of:   

   define i32 (i32 %a) {
  %b = alloca i32
  %2 = icmp eq i32 %a, 0
  br i1 %2, label %cond.yes, label %cond.no

cond.yes:
  store i32 5, ptr %b
  br label %cond.resume

cond.no: 
  store i32 %a, ptr %b
  br label %cond.resume

cond.resume:
  %out= load i32, ptr %b
  ret i32 %out
}
   

   Do you see the difference?   

   The one with the phi is shorter and doesn't use stack variables.   

   -> Less stack variables means (in most cases) more performant   

   What does it mean to ygen?   

   The addition of the    phi    node to ygen means that it is now possible to write an optimization pass (in llvm it is called:    mem2reg   ) which optimizes these    store   ,    loads    into a    phi   

   
   I hope I explained everything correctly.   
If I made any errors please correct me   
   

   GitHub-Link:    https://github.com/Cr0a3/ygen   

   Have a nice day   

   Cr0a3   
   

======>
https://old.reddit.com/r/rust/comments/1fwgihn/using_clap_for_entirely_the_wrong_purpose/
-->>-->>
Hi,   

   As the title suggests, I'm using the    clap    crate for something it's entirely not supposed to be used for. Long story short, I am trying to set up a REPL (which it    can    be used for   , though that's not super important) that parses commands that are multiple words and do not contain flags (   -f    and    --flag   ).   

   Here are are some example commands that I would like to parse:   

   
   toggle <FEATURE NAME> [ on | off ]   

   login name <USER NAME> key <digits>   

   setup [ init | position <POSITION STRING> ]   

   apply <STRING1> [STRING2 ... STRINGN]   
   

   For simple commands, like    toggle <FEATURE> [ on | off ]    I have been able to get this to work by using some features like    ValueEnum   . And, for the more complicated commands like    setup [ init | position <STRING> ]    I have been able to get a mock-up to work by nesting    sub commands   .   

   However, what I cannot figure out is how to get clap to parse a command whose argument is a single word. For example, I can parse    toggle Debug on    just fine. but I can't parse    toggle Debug Info on   .   

   I would like to know if anyone has worked with Clap enough to know of a solution to this.   
   

======>
https://old.reddit.com/r/rust/comments/1fwdge9/komorebi_v0129_status_bar_written_in_egui/
-->>-->>
Hi friends,   

   You may recall a post I made a little while ago about    building a status bar with egui    and documenting the process in a development video series.   

   Well, the status bar has now been released as part of    komorebi v0.1.29   !   

   If you're interested in seeing what a status bar written in egui can look like (custom fonts, hot-reloading, custom themes etc.), there is a deep dive into the bar and the configuration system here:    https://www.youtube.com/watch?v=eH4FSAD3dYs   

   If you're interested in trying it out, there is also a    quickstart video    which will get you up and running in less than 5 minutes.   
   

======>
https://github.com/Byron/gitoxide/discussions/1614
-->>-->>
Discussion options {{title}} Something went wrong. Quote reply Byron Oct 4, 2024 Maintainer Original comment in English - Translate to English This month was quite incredible in terms of features, but particularly so in terms of community. Merge Base support There are now various functions related to computing the merge-base of two or more commits, which an API that excells when multiple calls for queries on the same commit-graph are made. The idea is that the commit-graph is used as cache so future queries will be able to re-use at least some parts of it. It's notable that git2 already does that implicitly and thus also performs very well in comparison, which if you think about it is really nice. gix , however, prefers to make the usage of caches explicit so they can be dropped easily, while making clear that memory usage will grow here. The feature was sponsored by GitButler which can perform a lot of merge-base queries in a row - now it does that ever so slightly faster, but also can do so more easily in threads. Thanks to this implementation, listing branches and obtaining branch details is now fully driven by gix , and at least twice as fast as certain inter-dependent operations can now run in parallel. Tree Editing To support the upcoming tree-merge feature, high-performance tree-editing was implemented. As it supports cursors as well, I'd hope that performance will never be an issue for it. Cursors can be placed as sub-trees, allowing edit operations to start at this subtree right away to save some of the lookups required to find the in-memory structure that should receive the edit. Except for merges, tree-editing also enables users to generate their own trees, for instance to create a procedural commit. Repository::edit_tree() will get you started. In-Memory Object Writing When editing trees, or performing any other operation that writes a lot of objects, it's often useful to be able to avoid writing them to disk. That way, they can either be conditionally discarded, or they could be written into a pack all at once, avoiding lots of IO that would happen when writing many loose objects serially. Repository::with_object_memory() will enable it on the given repository instance, and it's typically used like gix::open(path)?.with_object_memory() . Blob-Merging (work-in-progress) On the way towards doing a full multi-root tree merge, it's required to handle a blob-merge as well, with conflict markers and resolution modes and everything. It took a while to finish the research and get started, but by now and 2300 lines of code later it's shaping up neatly with the 'big picture' of the algorithm already implemented and all baseline tests (i.e. comparisons to Git) passing. Still a lot of work to be done though to capture all the details and wire it up to gix . Security How configuration path resolution can be abused Eliah was busy and found an (already fixed) vulnerability where an attacker could abuse the incorrect decoding of quoted configuration file paths to have a gitoxide program access a configuration file path under the attackers control. Community The GitMerge 2024 in Berlin I have Scott Chacon and GitButler to thank for having been invited to the GitMerge conference to talk about gitoxide , and meet many fantastic people, with each and everyone being involved in Git. It was like heaven and felt a little bit like a vacation, too. During the second day, I could get 'upstairs' to the core developer session about Rust in Git and witness a possibly historic gettogether, and maybe one that will be the reason for Rust finally landing in Git to modernize it, and make it more maintainable. Also as part of the day two unconference, I was sharing everything there is to know about precious files in gitoxide , maybe to help them along getting implemented in Git, it was great fun, particularly because Elijah Newren, the author of the technical document, joined us in just the right moment to chime in. Overall, the conference was an event that is impossible to forget, with my only regret being that I didn't take enough pictures! Nobody will believe me otherwise :D. Gitoxide and the Sovereign Tech Fund Did you know that Ed Thomson, the maintainer of libgit2 , was at GitMerge to present? His talk was my personal highlight, with the added bonus him announcing that the libgit2 Drips donation will now be made available via Open Collective . To make it even better he shared his intention to donate some of that to git2 (the Rust wrapper crate) and gitoxide as well - this will be my incentive to get gitoxide onto Open Collective, and maybe that's a first step towards finally applying for funding from the Sovereign Tech Fund. Faster CI It took @NobodyXu just a few tweaks to make CI run significantly faster. And as so often, it wasn't the faster CPU that caused it, but a reduction of waste! And what's best is that one truly notices it. With that I'd think that CI can now beome slower again, but by running more tests, and even that won't be an impediment as 'auto-merge' now has arrived as well, so no more waiting for CI is needed. All in all, gitoxide CI definitely is in a very good spot now (particularly since Eliah Kagan re-enabled fuzzing as well). 'Blame' is getting there Thanks to @cruessler continuous work 'blame' is growing strong , and clocks in at nearly 2500 lines of code. I still owe a review but would hope that this first PR can be merged without much delay so it can be merged available in higher layers. Gix in Cargo Nothing changed, and it's a bit sad that none fo the GitButler -driven improvements thus far are applicable to push the Cargo integration forward. However, reset is done a lot, also in Cargo, so I'd hope this to be another avenue to finally that get last 'tree-index-status' part done which has been on my list for way too long already. Cheers Sebastian PS: The latest timesheets can be found here (2024) . Beta Was this translation helpful? Give feedback. 7 You must be logged in to vote 12 6 10 All reactions 12 6 10 Replies: 0 comments Sign up for free to join this conversation on GitHub .
    Already have an account? Sign in to comment
======>
https://old.reddit.com/r/rust/comments/1fwbdxs/llm_client005_the_easiest_way_to_integrate/
-->>-->>
Installable via    crates.io    - automatically builds for windows, linux, mac with or without CUDA.   

   It's kind of like a Rust Ollama, but the focus is on using LLMs to replace traditional control flow (if statements).   

   let response: u32 = llm_client.reason().integer()
    .instructions()
    .set_content("Sally (a girl) has 3 brothers. Each brother has 2 sisters. How many sisters does Sally have?")
    .return_primitive().await?;
   

   This performs CoT reasoning and returns a number (or boolean or custom string value) you can use in your code. With a small model like phi3.5 and a GPU, it can perform this process in around a second. So, the idea is to use it for agent behavior and NLP tasks.   

   Also, based on your available VRAM it will estimate the largest quant for the selected model, but you can also specify local models or device configs, or even run multiple models at once.   

   The goal is to make it as easy to use as possible - so building from a crates install was a big goal. It turns out it wasn't so bad, but I did have to buy a macbook to test it on!   

   https://github.com/shelbyJenkins/llm_client   
   

======>
https://old.reddit.com/r/rust/comments/1fvzfnb/gg_a_fast_more_lightweight_ripgrep_alternative/
-->>-->>
Searching the tokio codebase   

   Hi there,   
Here's a small project akin to ripgrep.   
Feel free to play around with it :-)   
Cheers   

   https://github.com/alexpasmantier/grip-grab        
   

======>
https://vosen.github.io/ZLUDA/blog/zludas-third-life/
-->>-->>
The year of rebuild The ultimate goal is to bring "new" ZLUDA to a similar state as before the rollback in one year (Q3 2025). "Similar state" is very subjective here. I don't have precise criteria, but an application of similar complexity should work just as well. Not every pre-rollback application will be supported again due to new priorities (more below). The year of rebuild
